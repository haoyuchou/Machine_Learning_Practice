{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-cc0cd0be6e0f>:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = (iris.target == 0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "#  set max_iter and tol explicitly to \n",
    "# avoid warnings about the fact that their default value will change in future versions of Scikit-Learn.\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets of fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28 × 28 array rather than a 1D array of size 784\n",
    "X_train_full.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is int instead of float(in MNIST)\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the validation set\n",
    "# scale because we are going to use gradient descent\n",
    "# scale from (0,255) to (0,1),  by dividing by 255.\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "# instead of number 0 to 9, this is the class we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# this is a coat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "# instead of 1D of 784, 28*28\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # 300 neurons, dense hidden layer\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # 100 neurons, dense hidden layer\n",
    "# 2 hidden layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # dense output layer, 10 neurons, 1 per class\n",
    "# the classes are exclusive\n",
    "# multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# s35500 = 784*300 + 300 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x22f68b15730>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22f68b15dc0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22f7f2f7700>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22f7f2f7a90>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"sgd\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7237 - accuracy: 0.7644 - val_loss: 0.5207 - val_accuracy: 0.8234\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4844 - accuracy: 0.8316 - val_loss: 0.4349 - val_accuracy: 0.8526\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4393 - accuracy: 0.8455 - val_loss: 0.5306 - val_accuracy: 0.7992\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4125 - accuracy: 0.8564 - val_loss: 0.3916 - val_accuracy: 0.8654\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3940 - accuracy: 0.8620 - val_loss: 0.3752 - val_accuracy: 0.8690\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3754 - accuracy: 0.8675 - val_loss: 0.3708 - val_accuracy: 0.8728\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3633 - accuracy: 0.8715 - val_loss: 0.3629 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3519 - accuracy: 0.8749 - val_loss: 0.3860 - val_accuracy: 0.8608\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3417 - accuracy: 0.8788 - val_loss: 0.3590 - val_accuracy: 0.8702\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3323 - accuracy: 0.8825 - val_loss: 0.3425 - val_accuracy: 0.8770\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3244 - accuracy: 0.8833 - val_loss: 0.3433 - val_accuracy: 0.8782\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3150 - accuracy: 0.8864 - val_loss: 0.3301 - val_accuracy: 0.8816\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3082 - accuracy: 0.8890 - val_loss: 0.3263 - val_accuracy: 0.8878\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3025 - accuracy: 0.8913 - val_loss: 0.3403 - val_accuracy: 0.8776\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2950 - accuracy: 0.8937 - val_loss: 0.3215 - val_accuracy: 0.8866\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2893 - accuracy: 0.8969 - val_loss: 0.3091 - val_accuracy: 0.8906\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2842 - accuracy: 0.8975 - val_loss: 0.3563 - val_accuracy: 0.8724\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2779 - accuracy: 0.9000 - val_loss: 0.3135 - val_accuracy: 0.8902\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2731 - accuracy: 0.9024 - val_loss: 0.3125 - val_accuracy: 0.8904\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2677 - accuracy: 0.9036 - val_loss: 0.3280 - val_accuracy: 0.8820\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2625 - accuracy: 0.9059 - val_loss: 0.3065 - val_accuracy: 0.8918\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2578 - accuracy: 0.9073 - val_loss: 0.2978 - val_accuracy: 0.8966\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2536 - accuracy: 0.9081 - val_loss: 0.2978 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2486 - accuracy: 0.9102 - val_loss: 0.3082 - val_accuracy: 0.8880\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2445 - accuracy: 0.9117 - val_loss: 0.2975 - val_accuracy: 0.8964\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2407 - accuracy: 0.9128 - val_loss: 0.3062 - val_accuracy: 0.8886\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2366 - accuracy: 0.9152 - val_loss: 0.3008 - val_accuracy: 0.8940\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2329 - accuracy: 0.9161 - val_loss: 0.2985 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2285 - accuracy: 0.9184 - val_loss: 0.3051 - val_accuracy: 0.8906\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2255 - accuracy: 0.9192 - val_loss: 0.3052 - val_accuracy: 0.8918\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "validation_data=(X_valid, y_valid))\n",
    "# epochs' default is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seems not much overfitting\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# validation curves are close to the training\n",
    "# curves, which means that there is not too much overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33928123116493225, 0.8822000026702881]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_new)\n",
    "    # sotfmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96],\n",
       "       [0.  , 0.  , 0.98, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure fashion_mnist_images_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "# model = keras.models.Sequential([\n",
    "# keras.layers.Flatten(input_shape=[28, 28]),\n",
    "# keras.layers.Dense(300, activation=\"relu\"),\n",
    "# keras.layers.Dense(100, activation=\"relu\"),\n",
    "# keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7987 - val_loss: 0.6806\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5335 - val_loss: 0.5710\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6129 - val_loss: 0.4964\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4694 - val_loss: 0.4785\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4616\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4350 - val_loss: 0.4553\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4433\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.4447\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4116 - val_loss: 0.4327\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4080 - val_loss: 0.4306\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4026 - val_loss: 0.4265\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4245\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3949 - val_loss: 0.4244\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4323\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.4283\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4093\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4162\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3790 - val_loss: 0.4066\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4046\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 0.4058\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3843\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmRElEQVR4nO3deZhcdZn28e9TVV29r+lOZycJSUAS2RIWQSBxAZ0BYUSdEQScccQR9XJ/9fWVUdFRx5lxxhkRl2FRRII6gIi7kgjInhGEYEhIQmcjS2ev3qqr+3n/ONXd1Z3q7uru6nTl9P25rnPVqVO/Oufpk8p9qn5nM3dHRETCJTLRBYiISP4p3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIZRTuJvZ+83sKTPrMLPbhmn7YTPbaWYHzewWMyvOS6UiIpKzXL+57wC+ANwyVCMzuwj4JPBaYC4wH/jcGOoTEZFRyCnc3f1ud78X2DtM02uAm919rbvvBz4PvHNMFYqIyIjF8jy/xcBPMp4/AzSa2RR377dhMLNrgWsBSktLl86ePXtUC+zu7iYSKdxdB4VeHxR+japvbFTf2BRyfevXr29294asL7p7zgNB18xtQ7y+EXhDxvMiwIG5Q8136dKlPlqrVq0a9XuPhkKvz73wa1R9Y6P6xqaQ6wOe8kFyNd+bowRQlfG8Z/xwnpcjIiJDyHe4rwVOyXh+CrDLB3TJiIjI+Mr1UMiYmZUAUSBqZiVmlq2//nvAu8zsJDOrBT4N3Ja3akVEJCe5fnP/NNBGcJjjO9LjnzazOWaWMLM5AO7+S+ArwCqgKT18Ju9Vi4jIkHI6WsbdPwt8dpCXKwa0/Srw1TFVJSIiY1KYx/eIiMiYKNxFREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCSOEuIhJCCncRkRBSuIuIhJDCXUQkhBTuIiIhpHAXEQkhhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIaRwFxEJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCKKdwN7M6M7vHzFrMrMnMrhiknZnZF8xsu5kdNLPVZrY4vyWLiMhwcv3mfiOQBBqBK4GbBgnttwJ/B5wH1AGPArfnoU4RERmBYcPdzMqBy4Hr3T3h7g8D9wFXZWk+D3jY3Te5exfwfeCkfBac6emtB/jG0+20dKTGaxEiIsckc/ehG5idBjzi7qUZ0z4GXODulwxoexxwD/A3wGbgn4BF7n5ZlvleC1wL0NjYuHTlypUjLv75vV185cl2PnR6MadOjY34/UdDIpGgoqJiossYUqHXqPrGRvWNTSHXt2LFijXuvizri+4+5EDQxbJzwLR3A6uztI0DXwMcSBEE/LzhlrF06VIfjfbOlC/81P3+j/c+O6r3Hw2rVq2a6BKGVeg1qr6xUX1jU8j1AU/5ILmaS597AqgaMK0KOJyl7WeAM4DZQAnwOeABMyvLYTkjVhyLcmJdlN+v3zMesxcROWblEu7rgZiZLcyYdgqwNkvbU4C73H2bu6fc/TaglnHsd3/llCgv7W1ly97W8VqEiMgxZ9hwd/cW4G7gBjMrN7NzgUvJfhTMk8BbzazRzCJmdhVQBLyYz6IzLamPAvD7Dfr2LiLSI9dDIa8DSoHdwJ3Ae919rZnNMbOEmc1Jt/tn4BngaeAA8GHgcnc/kM+iM00rN2bWlPKgumZERHrldIiJu+8DLssyfQtQkfG8HXhfejgqzIzzF9Xz02d20NnVTVFUJ92KiIQiCS9Y1ECiI8X/Nu2f6FJERApCKML9nAVTiEaMB9XvLiIChCTcq0qKOH1ODQ+ub57oUkRECkIowh3g/IUNPLfjIHsTHRNdiojIhAtPuC9qwB0eflHf3kVEQhPuS2ZWU1tWxO9fUL+7iEhowj0aMV69sIEHNzTT3T30xdBERMIuNOEOcP7CepoTHfx556GJLkVEZEKFK9wXNQDoqBkRmfRCFe6NVSWcOK1SlyIQkUkvVOEOwdmqTzXt092ZRGRSC124n7+ogc4u57FNeye6FBGRCRO6cF82t5bSoqi6ZkRkUgtduBfHopw9v44HN2inqohMXqELdwi6ZjY3t+juTCIyaYU23EF3ZxKRySuU4T6/vlx3ZxKRSe2YD/doquWIacHdmRp4dONeOru6J6AqEZGJdWyH+/M/4VWPvhuaj7z/tu7OJCKT2bEd7rPPws3g3vdCd1e/l3R3JhGZzI7tcK+cxoaF18K2J+DRG/u9pLszichkdmyHO7B76vlw4sXwwBdgzwv9XtPdmURksjrmwx0zuPjfIV4edM909V1TRndnEpHJ6tgPd4CKqfCX/wbb18Aj/9k7WXdnEpHJKhzhDrDkzXDSZbD6S7DreUB3ZxKRySs84Q7Bt/fiqnT3TCeguzOJyOQUrnAvr4eLvwovPw0P/weguzOJyOQUrnAHOOlSWPIW+P0/w85ndXcmEZmUwhfuAH/xL1BaG3TPpJK6O5OITDrhDPeyOrjkP2Dns/DQv+nuTCIy6YQz3AFO/Es4+W/goX/ljOItujuTiEwq4Q13gDd+Gcrqif/0/bx6XoXuziQik0a4w720Ft70X7B7Le+P3pP3uzO5O7sOtedtfiIi+ZJTuJtZnZndY2YtZtZkZlcM0Xa+md1vZofNrNnMvpK/ckdh0YVw2js4+aVbOdk25u3uTO7OF3/+Z8764u9Y/cLuvMxTRCRfcv3mfiOQBBqBK4GbzGzxwEZmFgd+AzwATANmAd/PT6ljcNEXoXIaXyv5Fo+s256XWX5j9Ua+89BmYhHj3369HnedASsihWPYcDezcuBy4Hp3T7j7w8B9wFVZmr8T2OHuX3X3Fndvd/c/5bXi0Sipxt70X8zzbSzbfNOY7850x+NN/MuvXuCyU2fwT3+1hGe3H+TXz+/KU7EiImNnw33jNLPTgEfcvTRj2seAC9z9kgFtbwGKgHrgDOA54APu/myW+V4LXAvQ2Ni4dOXKlaP6AxKJBBUVFTm1rX366yzZ/1t+uuCL1Mw+aVTLe/zlFN98poOTG6J84LRiDPjUw20UReCGc0uJmI26volS6DWqvrFRfWNTyPWtWLFijbsvy/qiuw85AOcBOwdMezewOkvbXwOdwBuBOPBxYBMQH2oZS5cu9dFatWpVzm0PHtjrW/9xvu/90hL3ZOuIl7X6hd2+4FM/87fe9Ii3JVO90+/94zY/7hP3+31Pbx9TfROl0GtUfWOj+samkOsDnvJBcjWXPvcEUDVgWhVwOEvbNuBhd/+FuyeBfwWmAK/IYTnjrqq6jpvrPkJd+5bg5h4jsKZpH/9w+xoWTq3kv9+5jJKiaO9rF588g0WNFfz7b9eT0g25RaQA5BLu64GYmS3MmHYKsDZL2z8BBb1nsW7Jhdze9Xr80Ruh6dGc3vPnlw/xt7c+SWNVMd/9uzOpKinq93o0Ynz4dYvYtKeFnzy9YzzKFhEZkWHD3d1bgLuBG8ys3MzOBS4Fbs/S/PvA2Wb2OjOLAh8CmoE/56/ksTl/UQNf6nw7rWUz4SfXQbJlyPZNe1u4+pYnKIvHuP1dZ9FQWZy13UWLp3HS9Cq+9rsNY95hKyIyVrkeCnkdUArsBu4E3uvua81sjpklzGwOgLu/ALwD+Cawn2Aj8KZ0F01BWDKzmuKySm5r+Djs2wS/u2HQtrsPtXPVzU/Q2dXN7e86k9l1ZYO2jUSMj164iC37WvmfNdvGo3QRkZzlFO7uvs/dL3P3cnef4+4/SE/f4u4V7r4lo+3d7r7A3avcfbm7Z+u+mTA9d2e6dfss/Mz3wOPfhD/98Ih2B1qTXHXzEzQnOrjtb89kYWPlsPN+zYlTOXV2Df/5uw10pLrGo3wRkZyE+/IDg+i9O9OSj8Lc8+Ce98CzP+59vTWZ4u9ue5LNzS185+plnDq7Jqf5mgXf3nccbOeuJ7eOU/UiIsObnOGevjvT7zcl4Iq7YM45cPe74bm7Saa6ec/ta3h66wH+8+2nce6C+hHN+9UL6jlzbh1ff+BF2jv17V1EJsakDPd+d2eKlwcBP/ts/H/+nu/d/DUe2tDMl998Mm9YMm3E8zYzPnLhInYf7uD7jzWNQ/UiIsOblOEO9L87U3EFfsVdNJWexDU7Ps+3z9jB286YPep5nz1/Cq9eUM9NqzfSniroI0NFJKQmbbgPvDvTv6zewcX7PsjuypO4cO0nYd3PxjT/j1y4iL0tSX7b1JmPckVERmTShvuyubW9d2f6zoOb+MbqjbzprBOZ8b77Yfop8MNr4IVfjHr+p8+p5TUnTuUXL3VyqF0BLyJH16QN9+JYlLPn1/HjNdv4p5//mb88eTqfv3QJVloD77gbpi2BH14N63896mV85PWLaOmEWx7enL/CRURyMGnDHYKumZZkF+ctrOff33Yq0Uj6io6lNXDVPTD1FXDXlfDib0c1/yUzq1naGOXmhzZzoLVgzuMSkUlgUof7X58xm8+9aTHfumop8diAVVFaC1fdCw0nwJ1XwMYHRrWMyxbESSRTfPvBTWMvWEQkR5M63MviMa45Zy5l8dggDerg6vugfiHc+XbYtHrEy5hdGeHik2dw6x9eojnRMbaCRURyNKnDPSdldXD1T6BuPvzgb2DzgyOexYdet5COVBffXL1xHAoUETmSwj0X5fXBN/ja4+AHfw0vPTyitx/fUMFfnTaL2x9rYteh9nEqUkSkj8I9VxUNcM1PoXo23PE2aHpkRG//4GsX0tXt3LjqxXEqUESkj8J9JCqmBgFfNQPueCtseSznt86ZUsZbl81m5RNb2X6gbRyLFBFRuI9cZWMQ8BWN8P23wNYnc37rB16zAICvP7BhvKoTEQEU7qNTNR3eeX/QVfO9S+FH74QnvgO7nofuwe/CNKOmlLefOZsfPrWNpr1D3wFKRGQsBjkGUIZVNQOuuT+4k9NLD8Hae4LppXVw3Dm9g3X3v+zv+1YsYOWTW/na7zbw1bedevTrFpFJQeE+FtUz4c3fAnc40BTsZG36Q/C47n4Azo2Wwo5Xp8P+XKbOOI2rX3UcNz+8meuWL2DB1IoJ/iNEJIwU7vlgBrVzg+HUK4Jph3ZA0yPsevTHzDz4Evzuc8H0WCn/Z/pSqoum8bP7dvLBq98O8cHvzSoiMhoK9/FSNQNe+RY27K1n5vLl0NIMWx6FpkcoavoD10UeIbLtx/iXP4FNPwXmnA2zzwoeK6ZOdPUicoxTuB8t5fXwikuCATi0v5lP/cd3uKTyJd4Y3RLskH3060Hb2nn9w77+BIho37eI5E7hPkFqaus54by38N7frue8qnre8Jo63jBlF1P2/TE4fv7F38IzdwaNS6ph1pkw5yyYfTbMXKquHBEZksJ9Ar3ngvl0dnXz82df5v/9dD3/Dzhl9ulctPiNXLiikQWx3bD18SDstz4OD/wmeGMkBtNODr7Vz1oGVbOCXwbl9VBcFewDEJFJTeE+gUqKonzsohP46IWL2Lgnwa/W7uJXa3fylV++wFd++QLHN5Rz0eLTufC0v+Dki6uJtO+HbU+mA/9xeOpWeOwb/WcajUN5QxD0ZfV949key+r1C0AkpBTuBcDMWDC1kgVTK3nfigXsONDGb57fxa+f38m30rcAnFZVwutPauSixUs5a/nrKYpGIJWE5hcgsSvYYduyJ/3YM74HmjcEj6lBLnkQr2BpvBH2LQuuXV9/AjScGBz5E9XHQ+RYpf+9BWhGTSnXnDOXa86Zy4HWJA+s282v1u7kR2u2cvtjTVSVxHjtKxq5aHEj5y96BWXTXjn8TJMtGeG/p2/88E46NzweXOnyT3f1tY/GYcqCIPAbToT6RcHjlOMhVjx+f7yI5IXCvcDVlMV58+mzePPps2hLdvHQhj38au0ufrduF/f8cTvxaIS59WXMqy9nfkMF8zMea8vjfTOKlwdD7dwjlvGn1atZvnw5tB8KvunvWRcMzethxx9h7b2AB40tCnXz+gJ/ygKIRKGrE7o7obsrYzwFXamM8QGP3angBLDa47TxEMkzhfsxpDQe5cLF07hw8TRSXd088dI+HlzfzMY9CV7cneCBdbvp7PLe9rVlRb1BP6+hnPn1FRzfUM6cKWUUx6JHLqCkCmYtDYZMnW1B6Dev7wv+Peth/S+DgB6WQbQIIkXBzuBorG8ch2d2cMTGo/6E9K+GE6g4nIDkGcHGSURyonA/RsWiEc45vp5zjq/vnZbq6mbr/jY27UmwubmFjXta2LQnwer1e/jRmm297SIGs2rLmN9Qzrz6ctr3dtL+3E5m1pQys7aU2rIiLPOIm6JSmH5yMGTq6oSDW9MzTQd2tCj4Jt87XjT8MfpHbDxeCIYNv4LuFMsA1nwUqudAw6L+3UT1C6G4Mli+jhIS6aVwD5FYNMK8+iCwBzrU3slLzS1sSgf+xuYWNu9p4fFN+2jr7OLOdWt625YWRZlRU8KMmlJm1ZYyozoI/Rk1pcysKWVadUmwQzdaFNx+cKyG2njs28Rzq+9mydRYsPN4z7pg/0Bq4B2tDGIlEItDtDjo2onGB0zLeC1W3DdeXAHF1cFGoqQqeCxOP5ZU9z0vKhn733o0dXdDazMVhzfCulY4vCO4LMahl/vGE7uCDXBxZf+/u7giY1olxCv7Py+uSrepgspp2rAWIIX7JFFVUsTJs2o4eVZNv+nuzv2/Wc28xaezbX8bOw60sf1A3+OfXz5EcyLZ7z0Rg8aqkt6wn15dwvTqEqZV943XVxQTiYzxP3y0CBpOoLnhVXDB8r7p3V1wYEvwTX/vi5Bsha4OSHVAVzII/lSyb1qqIz2ehI7DGdPSbTsSgx9N1K+eeNbgP2nfQdh3Z5YNS/oxc7zfY3qDY8OdfTzEevTuYOf4oR1w+GU4tD0I757n3Z3pXz49s4oGYVw5PfjlM3950LXWcTg9JIJ59D4/HKy7oZRPhXnn9w21cxX2BUDhPsmZGZVxY8nMapbMrM7apr2zq3/o729j+4F2th9o5emtB/jlc+0ku/pfxz4WMRqrekI/2BBMy3g+vbqUhspioqPZAETS/fJ184CLRvFXZ5FKQjIB7QfToXYoeGw/lB7PfJ7x+sGtlLfshy3b0huLjr7H7s781JarWGlwTaOqGXDcq4IAr5rJc1v2suScC6FyRnDdokiW/S1DSXUEoZ883D/0Ow5D6z7Y9kRw4/jnfhy0r57TP+yrpuf/b5VhKdxlWCVF0WDHbEP2yxO7O3tbkuw82M7LB9vZebCNHQfb08/beHb7QX79/C6Sqf4bgGjEmFpZTENlMfUVxUwpj1NfGTw2VBYzpbyY+so4hzqcrm4f3YYgV7E4xOqgrG7Eb32y52ijgbq7g6Dv+dXQ79dFxiN+5Ht7+BCv9SivDwK9pCbrN+bmttXBJStGq6cbq3xK9tfPujaos3l9EPKbfx9c8vrp7wev1y/qC/q5541qHQPBMjoOQ2J3+tyO3cHhvKW1UHNccNRVeYN+NaQp3GXMzIz6iiCgB/v27+7sb+3k5YNtvHygnZcPBRuBlw+205xIsutQO2t3HGRvIkmq+8hA+9Dqn1NXHu8N/Cnl6Q1CRZzKkhjl8RjlxTHKi6PBYzwYryiOURaPEY9NwIXXIhGIlBx7ffWjYdZ7dBNnvjvYsO16Nh32D8IzK+HJ/w7aTnslzLsgCPs5ryLS1QH7X0qHdjq4E7uD8O59vgsSQ5yM16OorC/oa+f2jfc8FleO95ooGDmFu5nVATcDFwLNwP919x8M854HgBVAkbvncrychJiZUVcep648zuIZ2TcAEGwEDrZ10pxI0pzoYG8iyaN/fI666XPYk0iyN9FBc6KDZ/YfoPlwBy3JrkHnlSkejVBWHKU8HgsCPx385fEY1aVF1JQXUVsWp7asiJqyeL/xmrKiYAey5C4SgemnBMM5Hwh2ju/4Y/CtfvODGVdBNc7H4aEs8yibEtyruLwhuGBexdT00Nj3WFYPbftgf1OwgTjQFIwfaAp2vCcTR86zJh38PaFfUhXs/4jGB+x8D8ZL2nYF+zFixcF+oGj6MdsvBPdgP0jmuRzdXRnjnQOep4K/oXpm3v8Jcv3mfiOQBBqBU4Gfmdkz7r42W2Mzu3IE8xbpZWbpQI333qWqfN8LLF9+Qtb27Z1dJDpStHSkSHSkaE32PW/t6BtvSXYFjx0pWpIpWjq6ONyeYufBdg60dXKgNdnvHIGBKotj1JQXUVMahH1m+O/e3snup7ZSVVJEVUmMqtIiKktiVJYEj9owEITh7DOD4fyPQ2d70Fff9CibmrYy/5VnZYT21CDQo0W5zbuyEaa+4sjp7sE+gQMvBcHfE/r7m4INzZ/vy+k8jbMBHs/2N6U3CHj/sB6pV38YXvfZkb9vGMMGsJmVA5cDS9w9ATxsZvcBVwGfzNK+GvgMcDXwaH7LFemvpChKSVGU+oqxndXq7rQku9jfkuRAayf7W5Psbw3Ge54faE2yvzXYEDTtbWV/a5LD7cF/5jvX/WnQeZcWRanMCP2qkr7wryoJuo3Ki6OUxqOUxaOUFgXPe8bL4lHKiqOUxWOUFkXHd9/D0VJU0tsPv2X1auafvjz/yzAL9hOUT8m+z6G7KziiKNly5L6QjPF1zz3DiQvnZ0zr2YeSHiySPrcjljFE+07U632eHu89FyT9fMqC/P/tgPkwO2zM7DTgEXcvzZj2MeACd78kS/sbgReBe4DNDNItY2bXAtcCNDY2Ll25cuWo/oBEIkFFReHeh7TQ64PCr7GQ6+vqdpoPtmDFZbSlnNZOgseU09YJrT3jKWjt9PRr0NaZfkw5nd3DLydTUQRKohCPGsUxKIkapTEoiRmlsfR4xjRLdVBTUdJvWkkMSmNGPEL/E9YmQCH/+0Jh17dixYo17r4s22u5dJ1UAAcHTDsIHLFnwsyWAecCHwRmDTVTd/828G2AZcuWedajDXKwerAjFQpEodcHhV9j2OtLdXXT1tlFa7JnSPWOt6W7kFo7g/Ej2nR00ZIMuqQOtad4OZHicEeKlo5O+vZLG5D9WPVoxCiLp/c/FMcoj6d3SGeM9+yU7t1BXRyjIr3/orw4RnEsQlE0QlEsQjwaDEUxoygaIRaxYTceYf/3nSi5hHsCqBowrQo4nDnBzCLAN4APuntqor8NiBwrYtEIldEIlSU59jHnwN1pS++PeODBR1h8ylIOd3TS0tFFoqOTREcXifa+fRUtA/ZX7GtppTW9nyLRkaIjNcKfFxni0QhFUesN/6JohHgsPS0aoaO1jZs3Pk5pUborKp7uioqnu6qK0l1SmdPSbUqLor1HScWjkQn/FVJIcgn39UDMzBa6+4b0tFOAgTtTq4BlwF3pFdxzpsQ2M3uru2fbHy4i48DM0gEYY1p5hFfOGvwIpVykuroH7JTuC/5kqpvOrmBIdjmdmc9T6WldmdO83+s72hMcbk+x+1AHrZ0p2np+tXR25XSYf49Y+ldIeXGs/2O879dGWTz4RVKW/mVSFo9RUhSlOBahuChCcezI8UNJJ9GRojiW2y+RQjFsuLt7i5ndDdxgZn9PcLTMpcA5A5oeBGZkPJ8NPAEsBfbkpVoRmRCxaITq0gjVpfn7ddEj6PY494jp7k5Hqru3G6ot2dd11daZ2XXVlT5SKt2FlQw2Pq0dwfOdh9p7f4W0JoNurJFsNAB44FdAsI+2ONZ/IxCPRojHosRjEYrTv0riPV1Usf7Pg/f2n/bKWTUsPa42D2uyv1wPV7wOuAXYDewF3uvua81sDvA8cJK7bwF29rzBzHrO3Nil49xFZKTMrPdoqLrMexOMUU+XVUtHEPgdqW46Ul3BY2c3ya4uOjq7e6c/+/wLHDfv+L42qW46OvvGkz2PXd0kU8HGZX9rz6+W9GNPu/TzTO9dfvzEhbu77wMuyzJ9C8EO12zveYkhr3gkInL0ZXZZNVQOfwhtY8smlp+fh6ufprk7nV3eG/zjdfa0TjQSETmKzIx4zIJQH8ebjunUORGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCSOEuIhJCCncRkRBSuIuIhJDCXUQkhBTuIiIhpHAXEQkhhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIaRwFxEJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCSOEuIhJCOYW7mdWZ2T1m1mJmTWZ2xSDtrjGzNWZ2yMy2mdlXzCyW35JFRGQ4uX5zvxFIAo3AlcBNZrY4S7sy4ENAPXAW8FrgY2MvU0RERmLYb9VmVg5cDixx9wTwsJndB1wFfDKzrbvflPF0u5ndAazIY70iIpIDc/ehG5idBjzi7qUZ0z4GXODulwzz3nuBde7+ySyvXQtcC9DY2Lh05cqVI68eSCQSVFRUjOq9R0Oh1weFX6PqGxvVNzaFXN+KFSvWuPuyrC+6+5ADcB6wc8C0dwOrh3nf3wLbgPrhlrF06VIfrVWrVo36vUdDodfnXvg1qr6xUX1jU8j1AU/5ILmay87OBFA1YFoVcHiwN5jZZcCXgde5e3MOyxARkTzKZYfqeiBmZgszpp0CrM3W2MzeAHwHuMTdnx17iSIiMlLDhru7twB3AzeYWbmZnQtcCtw+sK2ZvQa4A7jc3Z/Id7EiIpKbXA+FvA4oBXYDdwLvdfe1ZjbHzBJmNifd7nqgGvh5enrCzH6R/7JFRGQoOZ1g5O77gMuyTN8CVGQ812GPIiIFQJcfEBEJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCSOEuIhJCCncRkRBSuIuIhJDCXUQkhBTuIiIhpHAXEQkhhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIaRwFxEJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICOUU7mZWZ2b3mFmLmTWZ2RVDtP2wme00s4NmdouZFeevXBERyUWu39xvBJJAI3AlcJOZLR7YyMwuAj4JvBaYC8wHPpeXSkVEJGfDhruZlQOXA9e7e8LdHwbuA67K0vwa4GZ3X+vu+4HPA+/MY70iIpKDWA5tFgFd7r4+Y9ozwAVZ2i4GfjKgXaOZTXH3vZkNzexa4Nr004SZvZB72f3UA82jfO/RUOj1QeHXqPrGRvWNTSHXd9xgL+QS7hXAwQHTDgKVObTtGa8E+oW7u38b+HYOyx+SmT3l7svGOp/xUuj1QeHXqPrGRvWNTaHXN5hc+twTQNWAaVXA4Rza9oxnaysiIuMkl3BfD8TMbGHGtFOAtVnark2/ltlu18AuGRERGV/Dhru7twB3AzeYWbmZnQtcCtyepfn3gHeZ2UlmVgt8Grgtj/VmM+aunXFW6PVB4deo+sZG9Y1NodeXlbn78I3M6oBbgNcT9J1/0t1/YGZzgOeBk9x9S7rtR4BPAKXA/wD/4O4d41S/iIhkkVO4i4jIsUWXHxARCSGFu4hICB0T4V7I17Yxs2Izuzld12Ez+6OZvXGQtu80sy4zS2QMy8ezvvRyV5tZe8YyBz1hbALWX2LA0GVm/zVI26Oy/szs/Wb2lJl1mNltA157rZmtM7NWM1tlZoOeRDKSz20+6jOzs83sN2a2z8z2mNmPzGz6EPPJ+XORp/rmmpkP+Pe7foj5HO31d+WA2lrT9S4dZD7jsv7y5ZgIdwr72jYxYCvBGbvVwPXAD81s7iDtH3X3ioxh9TjX1+P9Gcs8IVuDiVh/meuC4N+3DfjREG85GutvB/AFgoMIeplZPcGRY9cDdcBTwF1DzCenz22+6gNqCY7smEtw5uJh4NZh5jXs5yKP9fWoyVjm54eYz1Fdf+5+x4DP43XAJuB/h5jXeKy/vCj4cLcCv7aNu7e4+2fd/SV373b3+4HNQNatfYGb6GsDvQXYDTx0FJd5BHe/293vZcBZ1cCbgbXu/iN3bwc+C5xiZicOnMcIP7d5qc/df5Gu7ZC7twJfB84d6/LyVd9ITMT6y+Ia4Ht+jB51UvDhzuDXtsm2BV+cfi2zXaOZTRnH+voxs0aCmrOd5AVwmpk1m9l6M7vezHK5BEQ+fCm93D8M0ZUx0esvl/9ME7X+YMD6SZ8DspHsn8WRfG7Hy/kM/jnskcvnIt+azGybmd2a/jWUzYSuv3R32/kE5+4MZSLWX06OhXDP17Vtxp2ZFQF3AN9193VZmjwILAGmEnwreTvw8aNQ2icIulhmEvxs/6mZHZ+l3YStPwvOmbgA+O4QzSZq/fUYy2dxqLZ5Z2YnA//I0Osn189FvjQDZxB0GS0lWBd3DNJ2QtcfcDXwkLtvHqLN0V5/I3IshPsxcW0bM4sQnLWbBN6frY27b3L3zenum2eBGwi6IsaVuz/u7ofdvcPdvwv8AfiLLE0n8tpAVwMPD/WfaaLWX4axfBaHaptXZrYA+AXwQXcftItrBJ+LvEh3rzzl7il330Xw/+RCMxu4nmAC11/a1Qz9ReOor7+ROhbCveCvbWNmBtxMsOPncnfvzPGtDti4FTby5U7ktYGG/c+UxdFef/3WT7pf+HiyfxZH8rnNm3R3wm+Bz7t7tkuEDOVor8+e7rdsy5yQ9QdgwSVWZgA/HuFbJ+r/c3buXvADsBK4Eygn2EF0EFicpd0bgJ3ASQRHDjwAfPko1PdN4DGgYph2bwQa0+MnAs8Bnxnn2mqAi4ASgiN7rgRagBMKaP2dk66pshDWX3o9lQBfIvg11rPuGtKfvcvT0/4ZeGysn9s81jeTYB/Ax/P5uchjfWcBJxB8qZxCcKTRqkJZfxmvf5tg38+ErL+8fY4nuoAc/zHqgHvTK28LcEV6+hyCn29zMtp+BNgFHCI4DKx4nGs7jmCL3Z6upWe4cmB9wL+ma2shOMTqBqBonOtrAJ4k+Dl7gGAj9PpCWX/pZX4LuD3L9AlZfwRHwfiA4bPp114HrCM4ZHM1MDfjfZ8CfjHc53a86gM+kx7P/BwmstU31OdiHOt7O8GRZC3AywQ7K6cVyvpLv1aSXh+vzfK+o7L+8jXo2jIiIiF0LPS5i4jICCncRURCSOEuIhJCCncRkRBSuIuIhJDCXUQkhBTuIiIhpHAXEQmh/w/a589FSSSxCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use dataframe from history\n",
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build with functional API\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "# we call it like a function, passing it the input.\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we cna compile as usual, but we need to pass a pair of metrics \n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:] # features 0-4, features 2-7\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8477 - val_loss: 0.9433\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8274 - val_loss: 0.7340\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6994 - val_loss: 0.6661\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6445 - val_loss: 0.6275\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6084 - val_loss: 0.5982\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5811 - val_loss: 0.5781\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5591 - val_loss: 0.5581\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5405 - val_loss: 0.5437\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5250 - val_loss: 0.5306\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5126 - val_loss: 0.5215\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5022 - val_loss: 0.5136\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4943 - val_loss: 0.5063\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4883 - val_loss: 0.5013\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4838 - val_loss: 0.4973\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 0.4958\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4767 - val_loss: 0.4917\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4735 - val_loss: 0.4904\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4875\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4689 - val_loss: 0.4862\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4666 - val_loss: 0.4847\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4781\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an auxiliary output for regularization\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.1377 - main_output_loss: 1.9300 - aux_output_loss: 4.0068 - val_loss: 1.0631 - val_main_output_loss: 0.8288 - val_aux_output_loss: 3.1725\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9125 - main_output_loss: 0.7249 - aux_output_loss: 2.6008 - val_loss: 0.8148 - val_main_output_loss: 0.6557 - val_aux_output_loss: 2.2465\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7656 - main_output_loss: 0.6357 - aux_output_loss: 1.9353 - val_loss: 0.7374 - val_main_output_loss: 0.6142 - val_aux_output_loss: 1.8463\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7043 - main_output_loss: 0.5994 - aux_output_loss: 1.6482 - val_loss: 0.6974 - val_main_output_loss: 0.5923 - val_aux_output_loss: 1.6432\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6687 - main_output_loss: 0.5769 - aux_output_loss: 1.4948 - val_loss: 0.6679 - val_main_output_loss: 0.5734 - val_aux_output_loss: 1.5184\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6423 - main_output_loss: 0.5582 - aux_output_loss: 1.3996 - val_loss: 0.6461 - val_main_output_loss: 0.5585 - val_aux_output_loss: 1.4349\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6221 - main_output_loss: 0.5429 - aux_output_loss: 1.3343 - val_loss: 0.6277 - val_main_output_loss: 0.5473 - val_aux_output_loss: 1.3516\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6051 - main_output_loss: 0.5304 - aux_output_loss: 1.2780 - val_loss: 0.6127 - val_main_output_loss: 0.5371 - val_aux_output_loss: 1.2929\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5916 - main_output_loss: 0.5207 - aux_output_loss: 1.2301 - val_loss: 0.6003 - val_main_output_loss: 0.5287 - val_aux_output_loss: 1.2442\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5804 - main_output_loss: 0.5126 - aux_output_loss: 1.1915 - val_loss: 0.5902 - val_main_output_loss: 0.5219 - val_aux_output_loss: 1.2044\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5706 - main_output_loss: 0.5053 - aux_output_loss: 1.1584 - val_loss: 0.5816 - val_main_output_loss: 0.5165 - val_aux_output_loss: 1.1674\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5624 - main_output_loss: 0.4996 - aux_output_loss: 1.1278 - val_loss: 0.5748 - val_main_output_loss: 0.5128 - val_aux_output_loss: 1.1329\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5552 - main_output_loss: 0.4945 - aux_output_loss: 1.1011 - val_loss: 0.5682 - val_main_output_loss: 0.5082 - val_aux_output_loss: 1.1079\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5490 - main_output_loss: 0.4902 - aux_output_loss: 1.0784 - val_loss: 0.5618 - val_main_output_loss: 0.5039 - val_aux_output_loss: 1.0834\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5430 - main_output_loss: 0.4860 - aux_output_loss: 1.0558 - val_loss: 0.5579 - val_main_output_loss: 0.5019 - val_aux_output_loss: 1.0613\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5384 - main_output_loss: 0.4832 - aux_output_loss: 1.0347 - val_loss: 0.5527 - val_main_output_loss: 0.4983 - val_aux_output_loss: 1.0422\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5334 - main_output_loss: 0.4798 - aux_output_loss: 1.0162 - val_loss: 0.5493 - val_main_output_loss: 0.4966 - val_aux_output_loss: 1.0235\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5294 - main_output_loss: 0.4772 - aux_output_loss: 0.9991 - val_loss: 0.5454 - val_main_output_loss: 0.4942 - val_aux_output_loss: 1.0061\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5256 - main_output_loss: 0.4748 - aux_output_loss: 0.9823 - val_loss: 0.5413 - val_main_output_loss: 0.4914 - val_aux_output_loss: 0.9909\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5218 - main_output_loss: 0.4724 - aux_output_loss: 0.9672 - val_loss: 0.5388 - val_main_output_loss: 0.4903 - val_aux_output_loss: 0.9755\n"
     ]
    }
   ],
   "source": [
    "#  the main output and the auxiliary output should try to predict the same thing\n",
    "history = model.fit(\n",
    "[X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 0s - loss: 0.6477 - main_output_loss: 0.5755 - aux_output_loss: 1.2971WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0157s). Check your callbacks.\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5287 - main_output_loss: 0.4825 - aux_output_loss: 0.9444\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "[X_test_A, X_test_B], [y_test, y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and restoring\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.8688 - val_loss: 0.7796\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7040 - val_loss: 0.6453\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6180 - val_loss: 0.6001\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5762 - val_loss: 0.5717\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5496 - val_loss: 0.5476\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5267 - val_loss: 0.5303\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5100 - val_loss: 0.5157\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4960 - val_loss: 0.5045\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4856 - val_loss: 0.4955\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.4883\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4842\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using callback during training\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8688\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7040\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6180\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5762\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5496\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5267\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5100\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4960\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4856\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4771\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4696 - val_loss: 0.4839\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4642 - val_loss: 0.4775\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4728\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4550 - val_loss: 0.4719\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4533 - val_loss: 0.4663\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4484 - val_loss: 0.4643\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4614\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4428 - val_loss: 0.4594\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4407 - val_loss: 0.4571\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4388 - val_loss: 0.4549\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid),\n",
    "callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4362 - val_loss: 0.4546\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4345 - val_loss: 0.4509\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4328 - val_loss: 0.4484\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4503\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4312 - val_loss: 0.4455\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4276 - val_loss: 0.4454\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4257 - val_loss: 0.4432\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4238 - val_loss: 0.4424\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4226 - val_loss: 0.4411\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4214 - val_loss: 0.4397\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4390\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4186 - val_loss: 0.4372\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4172 - val_loss: 0.4361\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4159 - val_loss: 0.4352\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4146 - val_loss: 0.4360\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4136 - val_loss: 0.4331\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4119 - val_loss: 0.4337\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4113 - val_loss: 0.4314\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4307\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.4309\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4073 - val_loss: 0.4301\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.4283\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.4267\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 0.4245\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4030 - val_loss: 0.4262\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.4250\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.4235\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4211\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4222\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3989 - val_loss: 0.4201\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.4249\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.4195\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3953 - val_loss: 0.4191\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3934 - val_loss: 0.4184\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3942 - val_loss: 0.4156\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3943 - val_loss: 0.4160\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3919 - val_loss: 0.4148\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.4135\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4143\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4125\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.4114\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3866 - val_loss: 0.4117\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3852 - val_loss: 0.4092\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3849 - val_loss: 0.4077\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 0.4080\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.4072\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.4068\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.4048\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.4051\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4058\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.4028\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.4049\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.4010\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3763 - val_loss: 0.4005\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4004\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.3991\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3739 - val_loss: 0.3985\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3733 - val_loss: 0.3967\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3964\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3716 - val_loss: 0.3975\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.3954\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3701 - val_loss: 0.3980\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3699 - val_loss: 0.3937\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.3956\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 0.3943\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.3920\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.3921\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3654 - val_loss: 0.3930\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3650 - val_loss: 0.3949\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.3929\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.3888\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3903\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3627 - val_loss: 0.3872\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.3879\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.3863\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3602 - val_loss: 0.3859\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3854\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3888\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3837\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3573 - val_loss: 0.3847\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.3826\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3860\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3833\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3827\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3539 - val_loss: 0.3826\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.3811\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3796\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3813\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3798\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3851\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3767\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3871\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3784\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.3832\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.359 - 1s 2ms/step - loss: 0.3544 - val_loss: 0.3757\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3874\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3578 - val_loss: 0.3766\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3586 - val_loss: 0.3798\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.3742\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.3829\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "restore_best_weights=True)\n",
    "# if no progress on validation sets for 10 epoch\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a custom callback\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/363 [===========================>..] - ETA: 0s - loss: 0.3492\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3750\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'\n",
    "\n",
    "# based on the time, so it is different everytime you run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "# clear before\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 8.4863WARNING:tensorflow:From C:\\Users\\haoyu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0488s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8688 - val_loss: 0.7796\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7040 - val_loss: 0.6453\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6180 - val_loss: 0.6001\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5762 - val_loss: 0.5717\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5496 - val_loss: 0.5476\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5267 - val_loss: 0.5303\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5100 - val_loss: 0.5157\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4960 - val_loss: 0.5045\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4856 - val_loss: 0.4955\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.4883\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4698 - val_loss: 0.4830\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4642 - val_loss: 0.4779\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4593 - val_loss: 0.4732\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4553 - val_loss: 0.4700\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4683\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4485 - val_loss: 0.4639\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4454 - val_loss: 0.4632\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4434 - val_loss: 0.4593\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4570\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4561\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4361 - val_loss: 0.4541\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4348 - val_loss: 0.4515\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4498\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4311 - val_loss: 0.4470\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.4475\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4275 - val_loss: 0.4463\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4435\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4415\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4225 - val_loss: 0.4417\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4214 - val_loss: 0.4397\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 16188."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_06_11-14_39_07'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))\n",
    "# learning rate is 0.05 this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/363 [..............................] - ETA: 1:58 - loss: 5.1471WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.6412s). Check your callbacks.\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.7432 - val_loss: 2.0988\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune the hyperparameters\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape)) # input\n",
    "    for layer in range(n_hidden):\n",
    "\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\")) # one hidden layer\n",
    "    model.add(keras.layers.Dense(1))  # output layer\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "# provide reasonable defaults to as many hyperparameters as you can\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0566 - val_loss: 0.7676\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6914 - val_loss: 0.6127\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5818 - val_loss: 0.5436\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5167 - val_loss: 0.5164\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4896 - val_loss: 0.4981\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4758 - val_loss: 0.4882\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4662 - val_loss: 0.4783\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4583 - val_loss: 0.4724\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4525 - val_loss: 0.4673\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4481 - val_loss: 0.4630\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4435 - val_loss: 0.4597\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4399 - val_loss: 0.4560\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4364 - val_loss: 0.4529\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4335 - val_loss: 0.4505\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4510\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4282 - val_loss: 0.4456\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4473\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4234 - val_loss: 0.4418\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4411\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4187 - val_loss: 0.4401\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.4370\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4357\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4323\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4110 - val_loss: 0.4305\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4086 - val_loss: 0.4330\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4072 - val_loss: 0.4328\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4283\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4038 - val_loss: 0.4257\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.4257\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4002 - val_loss: 0.4228\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4255\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3973 - val_loss: 0.4240\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4246\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3932 - val_loss: 0.4214\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3926 - val_loss: 0.4184\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4168\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4176\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3887 - val_loss: 0.4150\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.4158\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.4159\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.4110\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.4133\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.4093\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.4074\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3790 - val_loss: 0.4082\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.4059\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4072\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3752 - val_loss: 0.4068\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3743 - val_loss: 0.4040\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4052\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3724 - val_loss: 0.4044\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3714 - val_loss: 0.4040\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.3996\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 0.3995\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3687 - val_loss: 0.4026\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3985\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.3969\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.3963\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3967\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3643 - val_loss: 0.3970\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3634 - val_loss: 0.3960\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.3965\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.3935\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.3957\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3602 - val_loss: 0.3944\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3931\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.3929\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3580 - val_loss: 0.3963\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.3964\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.3976\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.3914\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.3908\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3547 - val_loss: 0.3895\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.3893\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3879\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3877\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3906\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3519 - val_loss: 0.3880\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3513 - val_loss: 0.3885\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3862\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3864\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.3913\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3492 - val_loss: 0.3876\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3484 - val_loss: 0.3862\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3926\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.3860\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3852\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3836\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3833\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3850\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3828\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3842\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3436 - val_loss: 0.3833\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3432 - val_loss: 0.3804\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3811\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3871\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3788\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.3781\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3412 - val_loss: 0.3783\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3406 - val_loss: 0.3789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f7f6027f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "# we can train this like a regular Scikit-Learn regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 840us/step - loss: 0.3601\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022F7F3B88B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "210/242 [=========================>....] - ETA: 0s - loss: 0.9188WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8870 - val_loss: 0.6316\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 0.5129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.4878\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.4760\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.4828\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.4700\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.4696\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4448 - val_loss: 0.4772\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.4657\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4611\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.4476\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.4542\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 0.4746\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4205 - val_loss: 0.4534\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.4446\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.4524\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.4412\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.4417\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4563\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4391\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.4480\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4406\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4504\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.4508\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4350\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.4444\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.5450\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4557\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4353\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.4509\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 0.4408\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.4364\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.4350\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 0.4332\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.4410\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.4565\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4314\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.4364\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.4283\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4036 - val_loss: 0.4333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4041 - val_loss: 0.4332\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4314\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.4277\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.4286\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.4464\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4026 - val_loss: 0.4517\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4245\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.4305\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4315\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4293\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.4391\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.4226\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.4326\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4280\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.4275\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.4356\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3919 - val_loss: 0.4891\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4218\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4309\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.4600\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.4234\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4197\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4536\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4284\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4306\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.4203\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4316\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.4236\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.4286\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3899 - val_loss: 0.4185\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.4218\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4227\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4291\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.4185\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4211\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.4217\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4130\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.4319\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4132\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4218\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.4169\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4233\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4145\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.4189\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4150\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.4105\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 0.4179\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4133\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.4189\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.4123\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3809 - val_loss: 0.4333\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4222\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.5414\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4166\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.4320\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4110\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.5390WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0016s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 792us/step - loss: 0.3837\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  42.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7680 - val_loss: 0.5515\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.5221\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5121\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5085\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.4950\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 0.4929\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4518 - val_loss: 0.4916\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4858\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4955\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4746\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.4738\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 0.4663\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.4800\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4278 - val_loss: 0.4821\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.4738\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4245 - val_loss: 0.4727\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 0.4641\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.4828\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4314 - val_loss: 0.5113\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 0.4817\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.4605\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4641\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4857\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.4588\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4169 - val_loss: 0.4666\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.4827\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.4559\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.4781\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 0.4749\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4599\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4085 - val_loss: 0.4615\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.4581\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4612\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.4647\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4523\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.4529\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4479\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.4448\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4488\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4400\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.4412\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.4417\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3908 - val_loss: 0.4420\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4354\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.4455\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4401\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.4390\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3878 - val_loss: 0.4314\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4314\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4334\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4393\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3878 - val_loss: 0.4301\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.4333\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4422\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3845 - val_loss: 0.4291\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4293\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.4413\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.4249\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4274\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4315\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4274\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.4437\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.4256\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.4419\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.4265\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.4246\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4241\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.4297\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4307\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4203\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4201\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.4222\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.4192\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.4152\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.4241\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.4242\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.4192\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.4158\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4136\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4207\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4152\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4220\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.4127\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.4238\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.4109\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4105\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.4185\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4105\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.4121\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4091\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4240\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4289\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.4265\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.4079\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.4062\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4081\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4048\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.4113\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.4107\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.4125\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3986\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  45.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8458 - val_loss: 0.5341\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.4953\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.4823\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.4755\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4877\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.4612\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4364 - val_loss: 0.4614\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4494\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.4757\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 0.4661\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.4510\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4391 - val_loss: 0.4969\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4226 - val_loss: 0.4473\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.4632\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4602\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.4457\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4520\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.4845\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4444\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.4539\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.4511\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.4406\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.4478\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.4484\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4394\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4391\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.4486\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4384\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4521\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 0.4393\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4346\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3960 - val_loss: 0.4425\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.4336\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.4412\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.4397\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.4294\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4426\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.4298\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.4345\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4232\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.4318\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.4294\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4315\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3802 - val_loss: 0.4307\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4279\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.4210\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4265\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4183\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4198\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.4146\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.4129\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.4170\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.4116\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4218\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.4159\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.4311\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.4256\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4080\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.4238\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4153\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.4073\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.4227\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4133\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.4056\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4199\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4081\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.4080\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.4177\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.4110\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.4087\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.4029\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.4196\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.4082\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.4012\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.4037\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4069\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4036\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.4086\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4008\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.4086\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4267\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.4388\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.4265\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4126\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.4062\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.4122\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.4053\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4029\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.4115\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3798\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  39.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9867 - val_loss: 0.6488\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5745 - val_loss: 0.5321\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4989 - val_loss: 0.4835\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4600 - val_loss: 0.4625\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4391 - val_loss: 0.4508\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4355\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4160 - val_loss: 0.4299\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4278\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4164\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4275\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4094\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.4046\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.4085\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3985\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4158\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3926\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3942\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3908\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3923\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3817\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.3860\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.3873\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3828\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3855\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3716\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.3732\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3793\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3328 - val_loss: 0.3703\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3638\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3268 - val_loss: 0.3696\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3263 - val_loss: 0.3672\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3624\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3237 - val_loss: 0.3609\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3206 - val_loss: 0.3595\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3625\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3175 - val_loss: 0.3632\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3628\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3561\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.3540\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3096 - val_loss: 0.3574\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3087 - val_loss: 0.3512\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3088 - val_loss: 0.3487\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3061 - val_loss: 0.3509\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3050 - val_loss: 0.3497\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3043 - val_loss: 0.3494\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3040 - val_loss: 0.3499\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3022 - val_loss: 0.3441\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3010 - val_loss: 0.3451\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3453\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2994 - val_loss: 0.3461\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2985 - val_loss: 0.3623\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2965 - val_loss: 0.3438\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.3485\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2951 - val_loss: 0.3439\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2932 - val_loss: 0.3482\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2931 - val_loss: 0.3434\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2923 - val_loss: 0.3524\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2914 - val_loss: 0.3413\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2901 - val_loss: 0.3456\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.3367\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2883 - val_loss: 0.3515\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2882 - val_loss: 0.3368\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2873 - val_loss: 0.3424\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2872 - val_loss: 0.3576\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2901 - val_loss: 0.3344\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2862 - val_loss: 0.3421\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2871 - val_loss: 0.3402\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2860 - val_loss: 0.3396\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2845 - val_loss: 0.3376\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2829 - val_loss: 0.3335\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2821 - val_loss: 0.3376\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2816 - val_loss: 0.3421\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2825 - val_loss: 0.3463\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2807 - val_loss: 0.3331\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2801 - val_loss: 0.3397\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2809 - val_loss: 0.3392\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.3396\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2787 - val_loss: 0.3424\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2771 - val_loss: 0.3519\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2782 - val_loss: 0.3307\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2777 - val_loss: 0.3350\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.3320\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2756 - val_loss: 0.3391\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2746 - val_loss: 0.3501\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2753 - val_loss: 0.3259\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2735 - val_loss: 0.3337\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2740 - val_loss: 0.3418\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2753 - val_loss: 0.3293\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2725 - val_loss: 0.3327\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.3308\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2704 - val_loss: 0.3393\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2728 - val_loss: 0.3347\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2709 - val_loss: 0.3452\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2721 - val_loss: 0.3327\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2701 - val_loss: 0.3368\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3156\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  50.5s\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 4.5278WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9053 - val_loss: 0.5942\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.5349\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5203 - val_loss: 0.4942\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.4769\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4525\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.4447\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.4371\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4313\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4296\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.4276\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3925 - val_loss: 0.4135\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4114\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.4092\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 0.4063\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4160\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3648 - val_loss: 0.3994\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3633 - val_loss: 0.4018\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.3933\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.3979\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.3922\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3851\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3884\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.3903\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3576 - val_loss: 0.3889\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3419 - val_loss: 0.3803\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3426 - val_loss: 0.3888\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.3766\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3344 - val_loss: 0.3818\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3457 - val_loss: 0.3848\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3779\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3336 - val_loss: 0.3713\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3269 - val_loss: 0.3670\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3690\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3218 - val_loss: 0.3662\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3187 - val_loss: 0.3645\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3180 - val_loss: 0.3627\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3139 - val_loss: 0.3662\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3140 - val_loss: 0.3608\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3118 - val_loss: 0.3597\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3104 - val_loss: 0.3578\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3070 - val_loss: 0.3572\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3575\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3555\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3539\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3035 - val_loss: 0.3537\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.3518\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3031 - val_loss: 0.3524\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2981 - val_loss: 0.3529\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2990 - val_loss: 0.3475\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2965 - val_loss: 0.3530\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2970 - val_loss: 0.3518\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2945 - val_loss: 0.3494\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2933 - val_loss: 0.3503\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2976 - val_loss: 0.3521\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2914 - val_loss: 0.3448\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.3451\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2904 - val_loss: 0.3485\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2899 - val_loss: 0.3478\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.3462\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.3422\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2872 - val_loss: 0.3443\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2884 - val_loss: 0.3500\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2939 - val_loss: 0.3402\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2846 - val_loss: 0.3491\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2879 - val_loss: 0.3393\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2830 - val_loss: 0.3434\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 0.3365\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2834 - val_loss: 0.3413\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 0.3397\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2816 - val_loss: 0.3363\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2797 - val_loss: 0.3351\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2792 - val_loss: 0.3406\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2793 - val_loss: 0.3365\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2784 - val_loss: 0.3385\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2779 - val_loss: 0.3374\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.3412\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.3406\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.3391\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2758 - val_loss: 0.3305\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.3387\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2754 - val_loss: 0.3338\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2743 - val_loss: 0.3325\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2727 - val_loss: 0.3355\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2729 - val_loss: 0.3358\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2748 - val_loss: 0.3320\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2721 - val_loss: 0.3375\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2759 - val_loss: 0.3387\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2723 - val_loss: 0.3332\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 0.3369\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3137\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  44.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1653 - val_loss: 0.7865\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0463 - val_loss: 0.9530\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5552 - val_loss: 0.5003\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4701 - val_loss: 0.4682\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4456 - val_loss: 0.4488\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.4375\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 0.4348\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.4243\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 0.4187\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4181\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4123\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4130\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.4052\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3802 - val_loss: 0.4062\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.4109\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3974\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.4001\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3647 - val_loss: 0.3947\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3634 - val_loss: 0.3899\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.3930\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3542 - val_loss: 0.3855\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 0.3817\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3485 - val_loss: 0.3877\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.3798\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.3759\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3408 - val_loss: 0.3791\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3707\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3359 - val_loss: 0.3737\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.3700\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.3673\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3704\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3678\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3252 - val_loss: 0.3655\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3657\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3577\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3748\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3178 - val_loss: 0.3561\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3154 - val_loss: 0.3587\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3152 - val_loss: 0.3538\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3111 - val_loss: 0.3537\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3580\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3107 - val_loss: 0.3581\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.3540\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3080 - val_loss: 0.3469\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3060 - val_loss: 0.3492\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.3551\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3031 - val_loss: 0.3533\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.3455\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3435\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2993 - val_loss: 0.3428\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2992 - val_loss: 0.3481\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.3455\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2971 - val_loss: 0.3470\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2973 - val_loss: 0.3470\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2973 - val_loss: 0.3454\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2958 - val_loss: 0.3459\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2961 - val_loss: 0.3370\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2946 - val_loss: 0.3406\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2924 - val_loss: 0.3420\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2911 - val_loss: 0.3367\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2884 - val_loss: 0.3406\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2894 - val_loss: 0.3392\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2877 - val_loss: 0.3344\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2857 - val_loss: 0.3492\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2863 - val_loss: 0.3341\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2845 - val_loss: 0.3345\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2848 - val_loss: 0.3380\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2831 - val_loss: 0.3354\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 0.3328\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2822 - val_loss: 0.3286\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2817 - val_loss: 0.3413\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.3294\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2798 - val_loss: 0.3280\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2805 - val_loss: 0.3290\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2799 - val_loss: 0.3252\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2785 - val_loss: 0.3339\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2788 - val_loss: 0.3345\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2782 - val_loss: 0.3242\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.3347\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2765 - val_loss: 0.3267\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2749 - val_loss: 0.3366\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2744 - val_loss: 0.3308\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.3361\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2758 - val_loss: 0.3258\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2744 - val_loss: 0.3288\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2746 - val_loss: 0.3284\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2745 - val_loss: 0.3266\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2740 - val_loss: 0.3373\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3073\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  45.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.1588 - val_loss: 2.7278\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9899 - val_loss: 1.6793\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3216 - val_loss: 1.3081\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0666 - val_loss: 1.1284\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 1.0234\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8772 - val_loss: 0.9569\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8348 - val_loss: 0.9093\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8051 - val_loss: 0.8738\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7825 - val_loss: 0.8451\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7640 - val_loss: 0.8210\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7481 - val_loss: 0.7998\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7341 - val_loss: 0.7813\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7212 - val_loss: 0.7643\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7095 - val_loss: 0.7489\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6985 - val_loss: 0.7350\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6882 - val_loss: 0.7221\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6785 - val_loss: 0.7099\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6694 - val_loss: 0.6987\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6608 - val_loss: 0.6883\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6527 - val_loss: 0.6782\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6449 - val_loss: 0.6686\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6377 - val_loss: 0.6600\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.6522\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6243 - val_loss: 0.6445\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6374\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 0.6305\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6240\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6178\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5954 - val_loss: 0.6120\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5904 - val_loss: 0.6062\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5855 - val_loss: 0.6009\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 0.5956\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5763 - val_loss: 0.5908\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5720 - val_loss: 0.5860\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5678 - val_loss: 0.5817\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - val_loss: 0.5775\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 0.5734\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5561 - val_loss: 0.5695\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 0.5655\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 0.5619\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.5583\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5423 - val_loss: 0.5549\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5392 - val_loss: 0.5515\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5361 - val_loss: 0.5484\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 0.5452\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 0.5422\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 0.5394\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.5366\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5338\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5312\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5167 - val_loss: 0.5285\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.5260\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5119 - val_loss: 0.5237\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 0.5214\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 0.5193\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.5170\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.5149\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5008 - val_loss: 0.5128\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 0.5110\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.5090\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.5071\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5054\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.5035\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5018\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5002\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.4987\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.4972\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.4958\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4815 - val_loss: 0.4942\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.4928\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.4914\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.4902\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.4889\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.4878\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.4865\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.4852\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.4840\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.4830\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.4819\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.4809\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.4798\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.4788\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.4779\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.4769\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.4759\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.4751\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.4742\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.4733\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.4724\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.4717\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.4709\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.4700\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4533 - val_loss: 0.4693\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.4686\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.4677\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.4671\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.4664\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.4658\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4483 - val_loss: 0.4651\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.4645\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4504\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  46.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4169 - val_loss: 2.0828\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6289 - val_loss: 1.2288\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0991 - val_loss: 0.9407\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8996 - val_loss: 0.8298\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8125 - val_loss: 0.7811\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7676 - val_loss: 0.7556\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7408 - val_loss: 0.7395\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7222 - val_loss: 0.7275\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7078 - val_loss: 0.7173\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6957 - val_loss: 0.7080\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6850 - val_loss: 0.6994\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6753 - val_loss: 0.6912\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6664 - val_loss: 0.6837\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6580 - val_loss: 0.6762\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6501 - val_loss: 0.6693\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 0.6624\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6357 - val_loss: 0.6558\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.6496\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.6440\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6381\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 0.6327\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6272\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.6221\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5949 - val_loss: 0.6174\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5901 - val_loss: 0.6127\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5854 - val_loss: 0.6082\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5811 - val_loss: 0.6041\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5768 - val_loss: 0.5999\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5727 - val_loss: 0.5961\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - val_loss: 0.5924\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5650 - val_loss: 0.5888\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.5851\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5578 - val_loss: 0.5820\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5545 - val_loss: 0.5786\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5512 - val_loss: 0.5753\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 0.5723\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 0.5695\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5422 - val_loss: 0.5666\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 0.5637\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.5611\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 0.5586\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 0.5562\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.5538\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 0.5517\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.5492\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5471\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 0.5452\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 0.5430\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5160 - val_loss: 0.5410\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 0.5393\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.5374\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5104 - val_loss: 0.5357\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 0.5340\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5325\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5309\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 0.5294\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5021 - val_loss: 0.5279\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.5265\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4991 - val_loss: 0.5251\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4976 - val_loss: 0.5236\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.5222\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.5210\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4935 - val_loss: 0.5196\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 0.5184\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5172\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5160\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5148\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5137\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.5127\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4853 - val_loss: 0.5116\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5107\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5097\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5087\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5078\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5069\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5060\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5052\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5043\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5034\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5026\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5019\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5012\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.5005\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.4997\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4990\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.4984\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.4977\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.4971\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.4964\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.4958\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.4951\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.4945\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.4939\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.4931\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.4925\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.4920\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.4914\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.4910\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.4903\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.4898\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4953\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  45.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.0569 - val_loss: 2.6944\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1770 - val_loss: 1.6767\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4516 - val_loss: 1.2189\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1160 - val_loss: 0.9933\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.8757\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8639 - val_loss: 0.8115\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8144 - val_loss: 0.7738\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7828 - val_loss: 0.7491\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7605 - val_loss: 0.7314\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7430 - val_loss: 0.7170\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7284 - val_loss: 0.7046\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7153 - val_loss: 0.6932\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7034 - val_loss: 0.6829\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6924 - val_loss: 0.6732\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6820 - val_loss: 0.6641\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6724 - val_loss: 0.6552\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6633 - val_loss: 0.6468\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6547 - val_loss: 0.6390\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6465 - val_loss: 0.6315\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6388 - val_loss: 0.6246\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6314 - val_loss: 0.6180\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 0.6117\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.6056\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6001\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.5946\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 0.5894\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5942 - val_loss: 0.5846\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5890 - val_loss: 0.5798\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5841 - val_loss: 0.5755\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 0.5713\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5749 - val_loss: 0.5673\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5706 - val_loss: 0.5635\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5665 - val_loss: 0.5599\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5626 - val_loss: 0.5564\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5589 - val_loss: 0.5530\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 0.5500\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.5471\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5487 - val_loss: 0.5443\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.5416\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.5389\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5399 - val_loss: 0.5365\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.5343\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.5320\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.5300\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5279\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.5259\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.5240\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5223\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5215 - val_loss: 0.5207\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5197 - val_loss: 0.5190\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.5174\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5161 - val_loss: 0.5159\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.5144\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.5131\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5118\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5097 - val_loss: 0.5104\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 0.5093\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5080\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.5068\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5057\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5046\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.5036\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 0.5026\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.5016\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5005\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4973 - val_loss: 0.4997\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.4987\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.4978\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.4970\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.4961\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 0.4954\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.4946\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.4938\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.4931\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.4923\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.4916\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4873 - val_loss: 0.4909\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.4904\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.4896\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.4890\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.4883\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.4877\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.4871\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.4865\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.4860\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.4855\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.4849\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.4844\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.4840\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.4833\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.4827\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.4822\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.4816\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.4812\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.4806\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.4802\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.4798\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.4792\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.4787\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4728 - val_loss: 0.4783\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4551\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  46.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.0375 - val_loss: 0.8751\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7635 - val_loss: 0.7222\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6744 - val_loss: 0.6640\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6254 - val_loss: 0.6207\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5886 - val_loss: 0.5888\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - val_loss: 0.5630\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.5426\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 0.5267\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5039 - val_loss: 0.5144\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.5074\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4818 - val_loss: 0.4963\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.4884\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.4845\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.4778\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.4765\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.4704\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.4674\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 0.4641\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4398 - val_loss: 0.4658\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 0.4581\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.4556\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.4552\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.4516\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4543\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.4471\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.4461\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.4423\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 0.4403\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4384\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.4374\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4100 - val_loss: 0.4357\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4085 - val_loss: 0.4329\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4317\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.4304\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.4293\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4282\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4256\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4270\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4238\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4217\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.4199\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.4182\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3910 - val_loss: 0.4175\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3898 - val_loss: 0.4163\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4153\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3865 - val_loss: 0.4161\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.4134\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4138\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4103\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.4104\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4089\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4080\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4076\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4069\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4059\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4088\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4070\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4057\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.4019\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4015\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.4003\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3993\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.3986\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.4020\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.3972\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 0.3990\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3966\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3628 - val_loss: 0.3957\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.3948\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.3948\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.3954\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.3936\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3941\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3922\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3948\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3549 - val_loss: 0.3913\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3906\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3530 - val_loss: 0.3905\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3521 - val_loss: 0.3889\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3516 - val_loss: 0.3894\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.3887\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3493 - val_loss: 0.3883\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3897\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3887\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3471 - val_loss: 0.3869\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.3860\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.3868\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3855\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 0.3842\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3427 - val_loss: 0.3861\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.3863\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.3849\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3411 - val_loss: 0.3909\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3835\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.3846\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3388 - val_loss: 0.3822\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3819\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3820\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.3818\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.3812\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3536\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  49.3s\n",
      "Epoch 1/100\n",
      "226/242 [===========================>..] - ETA: 0s - loss: 1.9689WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0029s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8952 - val_loss: 0.8302\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7222 - val_loss: 0.6864\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 0.6452\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.6119\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - val_loss: 0.5837\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5436 - val_loss: 0.5607\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.5402\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5041 - val_loss: 0.5243\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4895 - val_loss: 0.5109\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5003\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.4907\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.4827\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.4774\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4476 - val_loss: 0.4714\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4423 - val_loss: 0.4684\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4622\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.4589\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.4548\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.4537\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.4517\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.4459\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.4434\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4409\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4394\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.4361\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4385\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4063 - val_loss: 0.4328\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4039 - val_loss: 0.4328\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4292\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4285\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.4268\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4241\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4240\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.4219\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.4203\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.4196\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.4188\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4159\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.4159\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.4139\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.4136\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.4119\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4111\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.4101\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4087\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.4068\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.4074\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4052\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.4040\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4039\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4028\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.4038\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.4015\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4021\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.4006\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.4018\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.3997\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3630 - val_loss: 0.3994\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.3968\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3605 - val_loss: 0.3957\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.3972\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3957\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3624 - val_loss: 0.3944\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.3958\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3600 - val_loss: 0.3928\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3550 - val_loss: 0.3929\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.3913\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3930\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3916\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3924\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.3894\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.3900\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 0.3882\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3491 - val_loss: 0.3871\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3886\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.3859\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.3858\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3872\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3461 - val_loss: 0.3847\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3846\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3835\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3832\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3427 - val_loss: 0.3840\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3823\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3828\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.3835\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.3828\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3397 - val_loss: 0.3818\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.3792\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3805\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3813\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3372 - val_loss: 0.3826\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.3814\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3371 - val_loss: 0.3817\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.3767\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3773\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.3765\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3772\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.3760\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3776\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3642\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  49.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2494 - val_loss: 0.8544\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7630 - val_loss: 0.6778\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 0.6292\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6013\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5857 - val_loss: 0.5768\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 0.5578\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.5407\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5267\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5087 - val_loss: 0.5122\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.5017\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.4920\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.4846\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.4779\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.4717\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.4672\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.4602\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4564\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4527\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4473\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.4466\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4428\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.4397\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4361\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4146 - val_loss: 0.4369\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.4316\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.4294\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4284\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.4250\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4234\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.4219\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4190\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3965 - val_loss: 0.4188\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4179\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.4149\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.4135\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.4118\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3878 - val_loss: 0.4118\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4089\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4079\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.4059\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3813 - val_loss: 0.4076\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.4047\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4035\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4054\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.3998\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4008\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3999\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3977\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3973\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3962\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3953\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3949\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3927\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 0.3928\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.3924\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3635 - val_loss: 0.3918\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 0.3931\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.3891\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3605 - val_loss: 0.3887\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.3873\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 0.3865\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.3876\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3866\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3845\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3836\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3833\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3527 - val_loss: 0.3815\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3521 - val_loss: 0.3829\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3820\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.3798\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.3790\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.3787\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3477 - val_loss: 0.3790\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3770\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 0.3769\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3761\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3755\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.3780\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3427 - val_loss: 0.3744\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3744\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.3739\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3736\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.3743\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 0.3729\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.3724\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3741\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3367 - val_loss: 0.3706\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3722\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3351 - val_loss: 0.3731\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.3701\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.3699\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3335 - val_loss: 0.3705\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3328 - val_loss: 0.3694\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3678\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3315 - val_loss: 0.3666\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3687\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3675\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 0.3660\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3657\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3682\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3408\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  49.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9545 - val_loss: 0.5658\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 0.5368\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 0.5416\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5514\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.5528\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 0.5417\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 0.5473\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.5358\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5279 - val_loss: 0.5435\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 0.5478\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.5477\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5412\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5421 - val_loss: 0.5555\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.5356\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.5922\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 0.5408\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.5365\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5559\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.5689\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5616\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5431 - val_loss: 0.5545\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5801\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.5535\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 0.5693\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5594\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  11.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8061 - val_loss: 3.6814\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.2499 - val_loss: 63.2484\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2463.8347 - val_loss: 1249.6826\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7109.2505 - val_loss: 26922.6699\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 382949.0000 - val_loss: 579414.5000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 496396.6562 - val_loss: 12233805.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9175626.0000 - val_loss: 258873408.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5827213312.0000 - val_loss: 5170567680.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 32253196288.0000 - val_loss: 112642424832.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 706949677056.0000 - val_loss: 2452481376256.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 94564761206784.0000 - val_loss: 50087182991360.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1245586259968.0000\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   5.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0711 - val_loss: 2.7699\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.6009 - val_loss: 225.9023\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 617.0262 - val_loss: 19604.0625\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 46637.3086 - val_loss: 1738114.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4738955.5000 - val_loss: 153858048.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 308562784.0000 - val_loss: 13793975296.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 29652436992.0000 - val_loss: 1213246603264.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3987307233280.0000 - val_loss: 107353705807872.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 294056076771328.0000 - val_loss: 9507183913861120.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 27714519870472192.0000 - val_loss: 841984151757258752.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2704359899189477376.0000 - val_loss: 74465295804338798592.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 62750505185734295552.0000\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   5.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1372 - val_loss: 0.7222\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6590 - val_loss: 0.6209\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5723 - val_loss: 0.5482\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.4995\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.4738\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4587\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.4482\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.4427\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4313\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4036 - val_loss: 0.4421\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4232\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.4168\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.4242\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.4093\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.4104\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4025\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.4046\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3995\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.4037\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3946\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.3993\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.4021\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 0.3939\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.3950\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3822\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3450 - val_loss: 0.3852\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3825\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3842\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3753\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.3782\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3348 - val_loss: 0.3806\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3331 - val_loss: 0.3744\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3713\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.3723\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3696\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3260 - val_loss: 0.3796\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3239 - val_loss: 0.3804\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3219 - val_loss: 0.3643\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3205 - val_loss: 0.3651\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3178 - val_loss: 0.3699\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3177 - val_loss: 0.3602\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3158 - val_loss: 0.3610\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3145 - val_loss: 0.3613\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3133 - val_loss: 0.3599\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.3582\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3118 - val_loss: 0.3597\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.3537\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3527\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.3543\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3070 - val_loss: 0.3644\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3055 - val_loss: 0.3527\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3045 - val_loss: 0.3538\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3590\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3031 - val_loss: 0.3554\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2995 - val_loss: 0.3558\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3652\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.3588\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2994 - val_loss: 0.3559\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3218\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  28.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0027 - val_loss: 0.6549\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 0.5677\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5121 - val_loss: 0.5336\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.5063\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.4786\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 0.4669\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 0.4604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 0.4511\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.4458\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.4389\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.4309\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3953 - val_loss: 0.4260\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.4244\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.4194\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4216\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.4109\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.4112\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.4022\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.4027\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.4030\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3597 - val_loss: 0.3947\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3563 - val_loss: 0.3945\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3533 - val_loss: 0.3979\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3506 - val_loss: 0.3925\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.3847\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.3940\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 0.3829\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.3851\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.3817\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3843\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.3785\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.3718\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3757\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3712\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3685\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.3677\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3691\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3236 - val_loss: 0.3639\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3214 - val_loss: 0.3668\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3198 - val_loss: 0.3631\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3162 - val_loss: 0.3616\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3174 - val_loss: 0.3709\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3154 - val_loss: 0.3619\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3163 - val_loss: 0.3591\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3140 - val_loss: 0.3602\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.3571\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3114 - val_loss: 0.3556\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3091 - val_loss: 0.3611\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3082 - val_loss: 0.3529\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.3558\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3577\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3050 - val_loss: 0.3602\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.3518\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.3623\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.3507\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.3493\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3496\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2995 - val_loss: 0.3543\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.3591\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3474\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.3519\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2950 - val_loss: 0.3586\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2961 - val_loss: 0.3474\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.3556\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2963 - val_loss: 0.3477\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2927 - val_loss: 0.3514\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2915 - val_loss: 0.3436\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2929 - val_loss: 0.3571\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2917 - val_loss: 0.3477\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2927 - val_loss: 0.3435\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2893 - val_loss: 0.3447\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2886 - val_loss: 0.3502\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2879 - val_loss: 0.3429\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2875 - val_loss: 0.3494\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2880 - val_loss: 0.3428\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2893 - val_loss: 0.3485\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2863 - val_loss: 0.3479\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.3509\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2852 - val_loss: 0.3411\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2856 - val_loss: 0.3467\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2847 - val_loss: 0.3391\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2825 - val_loss: 0.3390\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.3385\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.3392\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.3403\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2815 - val_loss: 0.3490\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2847 - val_loss: 0.3437\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2812 - val_loss: 0.3418\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2799 - val_loss: 0.3498\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2797 - val_loss: 0.3360\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2782 - val_loss: 0.3406\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2799 - val_loss: 0.3454\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2770 - val_loss: 0.3463\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2796 - val_loss: 0.3385\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2784 - val_loss: 0.3374\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2773 - val_loss: 0.3371\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2764 - val_loss: 0.3353\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2775 - val_loss: 0.3386\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2757 - val_loss: 0.3460\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2769 - val_loss: 0.3417\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3243\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  48.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3339 - val_loss: 0.7103\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6934 - val_loss: 0.6745\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5811 - val_loss: 0.5367\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5043 - val_loss: 0.4988\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.4694\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.4542\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.4483\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.4339\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4268\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.4246\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4199\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4191\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.4105\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.4127\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.4209\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4028\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.4075\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3996\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3955\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3996\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3630 - val_loss: 0.4015\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.3924\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3894\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.3977\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3527 - val_loss: 0.3892\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.3849\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.3904\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.3831\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.3842\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.3800\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3770\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3785\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.3760\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.3758\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.3750\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3695\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3881\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3687\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3308 - val_loss: 0.3721\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 0.3689\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.3704\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3319 - val_loss: 0.3758\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.3767\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.3756\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3343 - val_loss: 0.3678\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3334 - val_loss: 0.3684\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3700\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3651\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3590\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3218 - val_loss: 0.3580\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3601\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 0.3651\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3168 - val_loss: 0.3571\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.3636\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3568\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3568\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3128 - val_loss: 0.3598\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3133 - val_loss: 0.3521\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3118 - val_loss: 0.3554\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3580\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3105 - val_loss: 0.3536\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.3533\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3091 - val_loss: 0.3597\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3084 - val_loss: 0.3488\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3051 - val_loss: 0.3716\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.3505\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3043 - val_loss: 0.3507\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3052 - val_loss: 0.3546\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3035 - val_loss: 0.3488\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.3481\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3026 - val_loss: 0.3442\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3592\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3436\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3457\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3468\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3023 - val_loss: 0.3440\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3024 - val_loss: 0.3493\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3048 - val_loss: 0.3529\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3457\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3768\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3591\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3196 - val_loss: 0.3549\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2986 - val_loss: 0.3466\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3142\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  40.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9628 - val_loss: 0.8238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7157 - val_loss: 0.6682\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6436 - val_loss: 0.6263\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.5980\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.5775\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.5590\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5445 - val_loss: 0.5443\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.5336\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 0.5229\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.5149\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.5068\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.5001\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.4964\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.4899\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.4874\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.4837\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.4802\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.4776\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.4780\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.4721\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.4698\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.4689\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.4665\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.4663\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4633\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4613\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4591\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4399 - val_loss: 0.4584\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4570\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4555\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.4553\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.4533\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4521\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 0.4513\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.4498\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.4502\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.4477\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.4478\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4459\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.4445\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 0.4434\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.4420\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.4420\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.4409\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4182 - val_loss: 0.4404\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.4400\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.4379\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.4380\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4357\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 0.4358\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.4349\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.4334\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.4330\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.4323\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4317\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.4337\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.4309\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.4304\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4038 - val_loss: 0.4281\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.4276\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4259\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.4269\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.4242\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.4250\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4233\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4232\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.4234\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4223\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.4215\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4206\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4206\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.4195\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.4186\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3904 - val_loss: 0.4184\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3895 - val_loss: 0.4176\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4170\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.4165\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4158\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 0.4142\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4140\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.4137\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.4132\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4139\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.4122\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.4118\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.4105\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.4107\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.4096\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4082\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4106\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.4096\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4084\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4101\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.4069\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.4067\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4054\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4050\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.4052\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4043\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.4037\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3813\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  45.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8093 - val_loss: 0.7901\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7128 - val_loss: 0.6796\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.6280\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5850 - val_loss: 0.5945\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.5686\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.5510\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5312\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5200\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5133\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5034\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.4962\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.4910\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.4869\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.4832\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.4763\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.4748\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4732\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4718\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4406 - val_loss: 0.4713\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 0.4682\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.4734\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.4694\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.4696\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.4620\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4640\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.4574\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4281 - val_loss: 0.4614\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4559\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4344 - val_loss: 0.4542\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4240 - val_loss: 0.4523\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 0.4498\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.4499\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.4477\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.4459\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.4467\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4451\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.4431\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4115 - val_loss: 0.4407\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.4408\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4086 - val_loss: 0.4393\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.4381\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4372\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 0.4363\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4040 - val_loss: 0.4347\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.4330\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.4333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.4314\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.4308\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4302\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4290\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4297\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.4275\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.4285\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3946 - val_loss: 0.4262\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4288\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.4250\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.4250\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.4225\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.4216\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4215\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.4226\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.4205\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.4204\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.4183\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.4178\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4196\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4171\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4172\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.4141\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.4153\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3809 - val_loss: 0.4123\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.4114\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.4131\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4105\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.4096\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4113\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4090\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4088\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.4077\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.4075\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4095\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4066\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4089\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.4084\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.4094\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.4054\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4029\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.4061\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.4072\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.4055\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.4048\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.4049\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.4025\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.4029\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.4012\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4021\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3985\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3993\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3896\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  46.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7209 - val_loss: 0.8865\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8109 - val_loss: 0.7923\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8285 - val_loss: 0.7340\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8660 - val_loss: 0.6354\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6246 - val_loss: 0.5781\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5664 - val_loss: 0.5610\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.5468\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5351 - val_loss: 0.5359\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 0.5264\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5189\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5126\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5011 - val_loss: 0.5074\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.5025\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.4976\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4851 - val_loss: 0.4950\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4810 - val_loss: 0.4885\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4770 - val_loss: 0.4852\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.4815\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4694 - val_loss: 0.4782\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.4760\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.4725\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.4696\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.4669\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.4650\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.4616\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.4598\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4584\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 0.4553\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 0.4536\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.4525\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.4504\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4485\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.4509\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.4455\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 0.4440\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.4426\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 0.4415\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4393\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4253 - val_loss: 0.4388\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.4382\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.4375\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.4350\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 0.4347\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4344\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4168 - val_loss: 0.4301\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4312\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.4294\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.4278\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4275\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.4278\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.4262\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 0.4257\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 0.4240\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.4233\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4040 - val_loss: 0.4231\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.4237\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4230\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.4197\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4192\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4185\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4176\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 0.4181\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.4174\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4157\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4157\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4153\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.4140\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.4141\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3905 - val_loss: 0.4138\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.4131\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4119\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4124\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.4107\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4097\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.4090\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.4087\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4077\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.4087\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.4069\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3814 - val_loss: 0.4071\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4063\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.4061\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.4066\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4056\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.4052\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4069\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.4038\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.4057\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.4049\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.4028\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.4036\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.4037\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.4025\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4011\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.4003\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4021\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4008\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3999\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3994\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.4012\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3750\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  46.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9768 - val_loss: 0.6443\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5696 - val_loss: 0.5166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.4657\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4540\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4164 - val_loss: 0.4374\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4045 - val_loss: 0.4211\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4158\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4337\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3809 - val_loss: 0.4054\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3727 - val_loss: 0.4190\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3962\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3928\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.4142\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3925\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.4200\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3798\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3829\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3819\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3355 - val_loss: 0.3915\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.3695\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3813\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3258 - val_loss: 0.3834\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.3924\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3219 - val_loss: 0.3746\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3223 - val_loss: 0.3696\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3192 - val_loss: 0.3631\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3159 - val_loss: 0.3715\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3136 - val_loss: 0.3578\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3128 - val_loss: 0.3564\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3074 - val_loss: 0.3616\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3075 - val_loss: 0.3657\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3058 - val_loss: 0.3527\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3049 - val_loss: 0.3506\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.3486\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2988 - val_loss: 0.3517\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2994 - val_loss: 0.3530\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2976 - val_loss: 0.3678\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.3454\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2946 - val_loss: 0.3439\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.3486\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2916 - val_loss: 0.3390\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2909 - val_loss: 0.3370\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2897 - val_loss: 0.3415\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2884 - val_loss: 0.3641\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2889 - val_loss: 0.3423\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2876 - val_loss: 0.3386\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2858 - val_loss: 0.3323\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2851 - val_loss: 0.3292\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.3494\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2879 - val_loss: 0.3367\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2828 - val_loss: 0.3408\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.3334\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2784 - val_loss: 0.3361\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2790 - val_loss: 0.3339\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 0.3369\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2777 - val_loss: 0.3359\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2774 - val_loss: 0.3370\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2762 - val_loss: 0.3258\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2739 - val_loss: 0.3387\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2742 - val_loss: 0.3203\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2735 - val_loss: 0.3287\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2730 - val_loss: 0.3218\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2704 - val_loss: 0.3312\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2727 - val_loss: 0.3368\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2746 - val_loss: 0.3216\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2714 - val_loss: 0.3282\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2701 - val_loss: 0.3303\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2733 - val_loss: 0.3388\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2697 - val_loss: 0.3268\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2703 - val_loss: 0.3222\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2945\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  37.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8635 - val_loss: 0.5969\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5234 - val_loss: 0.5169\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4701 - val_loss: 0.4901\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4673\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4309 - val_loss: 0.4428\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4163 - val_loss: 0.4349\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.4305\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3963 - val_loss: 0.4221\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.4172\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4090\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4050\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.4002\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.4005\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3974\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3976\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3882\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3845\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3801\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3390 - val_loss: 0.3818\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3368 - val_loss: 0.3862\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3325 - val_loss: 0.3737\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3785\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3325 - val_loss: 0.3857\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3309 - val_loss: 0.3729\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3228 - val_loss: 0.3687\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3168 - val_loss: 0.3829\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.3831\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3143 - val_loss: 0.3682\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3162 - val_loss: 0.3613\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3696\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3086 - val_loss: 0.3610\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3092 - val_loss: 0.3531\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3055 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3056 - val_loss: 0.3528\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3010 - val_loss: 0.3508\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3030 - val_loss: 0.3556\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2972 - val_loss: 0.3583\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3008 - val_loss: 0.3465\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2963 - val_loss: 0.3517\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2955 - val_loss: 0.3447\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2916 - val_loss: 0.3465\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2914 - val_loss: 0.3580\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2927 - val_loss: 0.3447\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2929 - val_loss: 0.3417\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2889 - val_loss: 0.3428\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2890 - val_loss: 0.3434\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.3418\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2858 - val_loss: 0.3524\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2864 - val_loss: 0.3380\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2836 - val_loss: 0.3485\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2856 - val_loss: 0.3403\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2814 - val_loss: 0.3413\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2814 - val_loss: 0.3418\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2855 - val_loss: 0.3491\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2791 - val_loss: 0.3356\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2773 - val_loss: 0.3360\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2781 - val_loss: 0.3381\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2779 - val_loss: 0.3413\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2769 - val_loss: 0.3439\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2746 - val_loss: 0.3356\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.3351\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.3446\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2768 - val_loss: 0.3299\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2711 - val_loss: 0.3411\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2762 - val_loss: 0.3338\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2702 - val_loss: 0.3447\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2710 - val_loss: 0.3273\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2717 - val_loss: 0.3376\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2699 - val_loss: 0.3319\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2705 - val_loss: 0.3289\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2672 - val_loss: 0.3290\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2667 - val_loss: 0.3390\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2664 - val_loss: 0.3293\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2654 - val_loss: 0.3359\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2653 - val_loss: 0.3269\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2665 - val_loss: 0.3337\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2641 - val_loss: 0.3428\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2642 - val_loss: 0.3338\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2655 - val_loss: 0.3215\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2657 - val_loss: 0.3345\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2638 - val_loss: 0.3248\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2607 - val_loss: 0.3204\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2585 - val_loss: 0.3261\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2595 - val_loss: 0.3286\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2624 - val_loss: 0.3228\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2576 - val_loss: 0.3323\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2604 - val_loss: 0.3334\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2576 - val_loss: 0.3231\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2577 - val_loss: 0.3417\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2575 - val_loss: 0.3185\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2552 - val_loss: 0.3284\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2579 - val_loss: 0.3461\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2529 - val_loss: 0.3431\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2577 - val_loss: 0.3205\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2563 - val_loss: 0.3234\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2543 - val_loss: 0.3245\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2541 - val_loss: 0.3208\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2571 - val_loss: 0.3270\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2530 - val_loss: 0.3220\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2527 - val_loss: 0.3246\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3032\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  53.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0015 - val_loss: 0.6116\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6261 - val_loss: 0.6136\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4966 - val_loss: 0.4722\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4411 - val_loss: 0.4433\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4225 - val_loss: 0.4288\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4103 - val_loss: 0.4233\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4005 - val_loss: 0.4147\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.4080\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3843 - val_loss: 0.4035\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3777 - val_loss: 0.4035\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3961\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3696 - val_loss: 0.3934\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3640 - val_loss: 0.3870\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3599 - val_loss: 0.3864\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3558 - val_loss: 0.3927\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3519 - val_loss: 0.3792\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.3869\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3715\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3694\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3728\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.3819\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3326 - val_loss: 0.3635\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3307 - val_loss: 0.3706\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3280 - val_loss: 0.3741\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3645\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3230 - val_loss: 0.3559\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3722\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3210 - val_loss: 0.3519\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3163 - val_loss: 0.3514\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3142 - val_loss: 0.3518\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3139 - val_loss: 0.3473\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.3496\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3077 - val_loss: 0.3476\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3059 - val_loss: 0.3467\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3055 - val_loss: 0.3591\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3051 - val_loss: 0.3376\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2997 - val_loss: 0.3951\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3369\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2983 - val_loss: 0.3467\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3358\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2947 - val_loss: 0.3350\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2967 - val_loss: 0.3648\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2950 - val_loss: 0.3525\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2928 - val_loss: 0.3410\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2935 - val_loss: 0.3335\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2964 - val_loss: 0.3349\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3000 - val_loss: 0.3427\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2956 - val_loss: 0.3400\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2878 - val_loss: 0.3259\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2864 - val_loss: 0.3249\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.3283\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2831 - val_loss: 0.3362\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2816 - val_loss: 0.3291\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2809 - val_loss: 0.3364\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2799 - val_loss: 0.3357\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2801 - val_loss: 0.3345\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2773 - val_loss: 0.3274\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2801 - val_loss: 0.3267\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2777 - val_loss: 0.3326\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2755 - val_loss: 0.3333\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3110\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  32.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8658 - val_loss: 0.5648\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5099 - val_loss: 0.4828\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4521 - val_loss: 0.4489\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4247 - val_loss: 0.4373\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4300\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.4174\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3903 - val_loss: 0.4144\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 0.4304\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.4061\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.4173\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3641 - val_loss: 0.3975\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3895\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3564 - val_loss: 0.4103\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3888\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.4018\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3796\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3802\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.3769\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3313 - val_loss: 0.3818\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3290 - val_loss: 0.3666\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3266 - val_loss: 0.3723\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3213 - val_loss: 0.3806\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3223 - val_loss: 0.3781\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3181 - val_loss: 0.3740\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3183 - val_loss: 0.3535\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3146 - val_loss: 0.3611\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3135 - val_loss: 0.3721\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3575\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3113 - val_loss: 0.3495\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3053 - val_loss: 0.3513\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3047 - val_loss: 0.3593\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3032 - val_loss: 0.3435\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3039 - val_loss: 0.3426\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.3485\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2967 - val_loss: 0.3450\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2980 - val_loss: 0.3507\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2955 - val_loss: 0.3677\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2949 - val_loss: 0.3381\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2928 - val_loss: 0.3368\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2901 - val_loss: 0.3434\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2903 - val_loss: 0.3309\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2882 - val_loss: 0.3314\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2881 - val_loss: 0.3310\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.3443\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2870 - val_loss: 0.3355\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2873 - val_loss: 0.3313\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2841 - val_loss: 0.3265\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.3238\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2819 - val_loss: 0.3260\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2817 - val_loss: 0.3342\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2812 - val_loss: 0.3267\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2793 - val_loss: 0.3302\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 0.3341\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2771 - val_loss: 0.3261\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2750 - val_loss: 0.3289\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2762 - val_loss: 0.3216\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2756 - val_loss: 0.3258\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2757 - val_loss: 0.3219\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2734 - val_loss: 0.3346\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2749 - val_loss: 0.3154\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2716 - val_loss: 0.3255\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2712 - val_loss: 0.3181\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2702 - val_loss: 0.3250\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2716 - val_loss: 0.3398\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2754 - val_loss: 0.3129\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2698 - val_loss: 0.3247\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2696 - val_loss: 0.3219\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2708 - val_loss: 0.3289\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2688 - val_loss: 0.3159\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2677 - val_loss: 0.3143\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2669 - val_loss: 0.3232\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2674 - val_loss: 0.3198\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2651 - val_loss: 0.3356\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2651 - val_loss: 0.3118\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2645 - val_loss: 0.3293\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2649 - val_loss: 0.3393\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2616 - val_loss: 0.3267\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2623 - val_loss: 0.3369\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2630 - val_loss: 0.3324\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2624 - val_loss: 0.3146\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2617 - val_loss: 0.3213\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2600 - val_loss: 0.3102\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2599 - val_loss: 0.3172\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2587 - val_loss: 0.3545\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2580 - val_loss: 0.3067\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2569 - val_loss: 0.3141\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2562 - val_loss: 0.3115\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2604 - val_loss: 0.3114\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2556 - val_loss: 0.3219\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2555 - val_loss: 0.3137\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2549 - val_loss: 0.3148\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2564 - val_loss: 0.3120\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2539 - val_loss: 0.3126\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2569 - val_loss: 0.3066\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2532 - val_loss: 0.3170\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2540 - val_loss: 0.3271\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2523 - val_loss: 0.3120\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2542 - val_loss: 0.3078\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2515 - val_loss: 0.3073\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2513 - val_loss: 0.3256\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2986\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  52.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8629 - val_loss: 0.5706\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4999 - val_loss: 0.5299\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5885 - val_loss: 0.5122\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4603 - val_loss: 0.4741\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4312 - val_loss: 0.4451\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4319\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4031 - val_loss: 0.4252\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4182\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3841 - val_loss: 0.4141\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3765 - val_loss: 0.4216\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3699 - val_loss: 0.4005\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3664 - val_loss: 0.3966\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.3975\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.3937\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.4129\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3464 - val_loss: 0.3860\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3850\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3375 - val_loss: 0.3765\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3782\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3786\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3695\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3760\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3823\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3715\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3631\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3118 - val_loss: 0.3844\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3139 - val_loss: 0.3733\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3102 - val_loss: 0.3629\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3099 - val_loss: 0.3603\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3085 - val_loss: 0.3630\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3040 - val_loss: 0.3615\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3049 - val_loss: 0.3516\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3021 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3019 - val_loss: 0.3506\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2968 - val_loss: 0.3507\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2993 - val_loss: 0.3531\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2939 - val_loss: 0.3579\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2979 - val_loss: 0.3444\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2925 - val_loss: 0.3496\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2913 - val_loss: 0.3432\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2867 - val_loss: 0.3469\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2881 - val_loss: 0.3508\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2872 - val_loss: 0.3439\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2884 - val_loss: 0.3420\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2850 - val_loss: 0.3434\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2850 - val_loss: 0.3415\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2852 - val_loss: 0.3390\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2807 - val_loss: 0.3418\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2810 - val_loss: 0.3344\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2793 - val_loss: 0.3394\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2788 - val_loss: 0.3358\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2770 - val_loss: 0.3350\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2744 - val_loss: 0.3385\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2783 - val_loss: 0.3434\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2740 - val_loss: 0.3375\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2721 - val_loss: 0.3302\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2724 - val_loss: 0.3300\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2724 - val_loss: 0.3394\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2718 - val_loss: 0.3432\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2695 - val_loss: 0.3336\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2687 - val_loss: 0.3336\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2695 - val_loss: 0.3387\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2709 - val_loss: 0.3256\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2660 - val_loss: 0.3440\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2717 - val_loss: 0.3312\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2657 - val_loss: 0.3484\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2663 - val_loss: 0.3255\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2654 - val_loss: 0.3302\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2641 - val_loss: 0.3279\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2659 - val_loss: 0.3244\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2629 - val_loss: 0.3215\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2621 - val_loss: 0.3297\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2609 - val_loss: 0.3260\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2600 - val_loss: 0.3366\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2602 - val_loss: 0.3224\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2620 - val_loss: 0.3387\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2591 - val_loss: 0.3423\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2589 - val_loss: 0.3371\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2600 - val_loss: 0.3168\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2603 - val_loss: 0.3278\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2587 - val_loss: 0.3213\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2564 - val_loss: 0.3181\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2543 - val_loss: 0.3226\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2548 - val_loss: 0.3299\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2566 - val_loss: 0.3191\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2532 - val_loss: 0.3319\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2559 - val_loss: 0.3268\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2534 - val_loss: 0.3177\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2530 - val_loss: 0.3553\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3391\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  48.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5364 - val_loss: 0.8187\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5727 - val_loss: 0.5353\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5103 - val_loss: 0.9382\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4866 - val_loss: 0.5325\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4792 - val_loss: 0.4562\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4361 - val_loss: 0.4404\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4178 - val_loss: 0.4310\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4187\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3935 - val_loss: 0.4120\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.4093\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.4019\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3716 - val_loss: 0.3993\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.3896\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.3924\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3537 - val_loss: 0.3951\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3480 - val_loss: 0.3798\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3447 - val_loss: 0.3816\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3700\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.3662\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3332 - val_loss: 0.3698\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.3760\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3257 - val_loss: 0.3608\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3633\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3197 - val_loss: 0.3691\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3158 - val_loss: 0.3590\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3150 - val_loss: 0.3494\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.3672\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3106 - val_loss: 0.3480\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3068 - val_loss: 0.3478\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3045 - val_loss: 0.3468\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3052 - val_loss: 0.3396\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3029 - val_loss: 0.3452\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2986 - val_loss: 0.3403\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2970 - val_loss: 0.3411\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2958 - val_loss: 0.3514\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2953 - val_loss: 0.3332\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2896 - val_loss: 0.3755\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2911 - val_loss: 0.3313\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2896 - val_loss: 0.3400\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2897 - val_loss: 0.3331\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2861 - val_loss: 0.3289\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2887 - val_loss: 0.3574\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2879 - val_loss: 0.3406\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2840 - val_loss: 0.3348\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2835 - val_loss: 0.3313\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2819 - val_loss: 0.3251\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2804 - val_loss: 0.3364\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2795 - val_loss: 0.3381\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2786 - val_loss: 0.3227\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2780 - val_loss: 0.3215\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2757 - val_loss: 0.3255\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2763 - val_loss: 0.3310\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2747 - val_loss: 0.3317\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2739 - val_loss: 0.3343\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2737 - val_loss: 0.3323\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.3290\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2716 - val_loss: 0.3299\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2732 - val_loss: 0.3259\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2713 - val_loss: 0.3329\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2705 - val_loss: 0.3381\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3160\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  32.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0696 - val_loss: 0.6401\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5713 - val_loss: 0.5392\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5087\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.4962\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.4809\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.4645\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4419 - val_loss: 0.4574\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4326 - val_loss: 0.4495\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.4460\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.4640\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.4358\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4100 - val_loss: 0.4331\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.4351\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.4240\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.4611\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4193\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.4247\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3888 - val_loss: 0.4199\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3851 - val_loss: 0.4190\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4099\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3809 - val_loss: 0.4153\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4199\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.4085\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.4135\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.4050\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.4048\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.4130\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3990\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.3920\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3578 - val_loss: 0.3959\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3970\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.3896\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3879\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3529 - val_loss: 0.3875\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.3990\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.3965\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3424 - val_loss: 0.3839\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3426 - val_loss: 0.3827\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3793\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.3804\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.3754\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.3735\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.3745\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3328 - val_loss: 0.3711\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3753\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3310 - val_loss: 0.3736\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3686\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3281 - val_loss: 0.3708\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3257 - val_loss: 0.3696\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3254 - val_loss: 0.3719\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3249 - val_loss: 0.4767\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3236 - val_loss: 0.3669\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3680\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3226 - val_loss: 0.3685\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3252 - val_loss: 0.3674\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3194 - val_loss: 0.4417\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3190 - val_loss: 0.3711\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3601\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3153 - val_loss: 0.3668\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3202 - val_loss: 0.3592\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3134 - val_loss: 0.3641\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3124 - val_loss: 0.3795\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3137 - val_loss: 0.3635\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.4261\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.3546\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3091 - val_loss: 0.3582\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.5226\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3129 - val_loss: 0.3580\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3080 - val_loss: 0.3514\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3048 - val_loss: 0.3528\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 0.3512\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.3606\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3084 - val_loss: 0.3501\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3033 - val_loss: 0.3506\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3030 - val_loss: 0.3587\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.3571\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3040 - val_loss: 0.3498\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.3592\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2989 - val_loss: 0.3516\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2999 - val_loss: 0.3488\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2992 - val_loss: 0.3455\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2979 - val_loss: 0.3468\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2967 - val_loss: 0.3553\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2952 - val_loss: 0.3519\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.3413\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2940 - val_loss: 0.3429\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2952 - val_loss: 0.3601\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.3423\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2932 - val_loss: 0.3407\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2924 - val_loss: 0.3413\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2897 - val_loss: 0.3462\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.3454\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2905 - val_loss: 0.3522\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2902 - val_loss: 0.3411\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2919 - val_loss: 0.3512\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2890 - val_loss: 0.3493\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.3383\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2885 - val_loss: 0.3452\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2871 - val_loss: 0.3417\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2858 - val_loss: 0.3521\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3125\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  49.3s\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 5.4874WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.\n",
      "235/242 [============================>.] - ETA: 0s - loss: 1.2329WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2119 - val_loss: 0.7086\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.5935\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5569 - val_loss: 0.5129\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.4796\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.4617\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.4501\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.4427\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4363\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4052 - val_loss: 0.4307\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.4291\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.4189\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3875 - val_loss: 0.4156\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4146\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.4098\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.4181\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4044\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.4052\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.3996\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 0.3997\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.3967\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.3933\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 0.3944\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3542 - val_loss: 0.3933\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3932\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.3863\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3461 - val_loss: 0.3941\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3837\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.3836\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3828\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.3812\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3830\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3757\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3352 - val_loss: 0.3775\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3355 - val_loss: 0.3741\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3319 - val_loss: 0.3738\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3720\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3803\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3721\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3700\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3708\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3235 - val_loss: 0.3693\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3237 - val_loss: 0.3682\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3240 - val_loss: 0.3692\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.3647\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3682\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3197 - val_loss: 0.3643\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3236 - val_loss: 0.3658\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3646\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3193 - val_loss: 0.3604\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.3649\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3657\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3128 - val_loss: 0.3600\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3118 - val_loss: 0.3609\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3172 - val_loss: 0.3637\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3097 - val_loss: 0.3562\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3563\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.3601\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.3586\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3568\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3052 - val_loss: 0.3548\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3060 - val_loss: 0.3595\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3102 - val_loss: 0.3583\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3151 - val_loss: 0.3537\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.3583\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.3507\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.3512\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2998 - val_loss: 0.3477\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3527\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 0.3494\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2975 - val_loss: 0.3477\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2959 - val_loss: 0.3462\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2957 - val_loss: 0.3492\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2951 - val_loss: 0.3453\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2944 - val_loss: 0.3462\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2940 - val_loss: 0.3467\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.3460\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.3456\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2914 - val_loss: 0.3461\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2907 - val_loss: 0.3402\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2908 - val_loss: 0.3475\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2907 - val_loss: 0.3413\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2883 - val_loss: 0.3414\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2875 - val_loss: 0.3403\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2874 - val_loss: 0.3430\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2881 - val_loss: 0.3393\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.3433\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2871 - val_loss: 0.3440\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2855 - val_loss: 0.3383\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2840 - val_loss: 0.3402\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2843 - val_loss: 0.3382\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2835 - val_loss: 0.3420\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.3447\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2816 - val_loss: 0.3504\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2834 - val_loss: 0.3359\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2830 - val_loss: 0.3347\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2814 - val_loss: 0.3367\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2811 - val_loss: 0.3322\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2801 - val_loss: 0.3380\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2796 - val_loss: 0.3373\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2796 - val_loss: 0.3429\n",
      "121/121 [==============================] - 0s 996us/step - loss: 0.3193\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  48.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2203 - val_loss: 0.6966\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7701 - val_loss: 1.0569\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7462 - val_loss: 0.5491\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5097\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.4820\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.4673\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4588\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 0.4473\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.4396\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4254 - val_loss: 0.4359\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4209 - val_loss: 0.4305\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.4291\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4103 - val_loss: 0.4225\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.4232\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4245\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3986 - val_loss: 0.4131\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.4151\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3904 - val_loss: 0.4111\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4055\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.4068\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.4064\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.4006\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3970\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4030\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3936\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3916\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.3929\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 0.3860\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3591 - val_loss: 0.3867\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.3849\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3550 - val_loss: 0.3813\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3527 - val_loss: 0.3847\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 0.3816\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3477 - val_loss: 0.3816\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3460 - val_loss: 0.3785\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 0.3726\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.3819\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3706\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3372 - val_loss: 0.3720\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3365 - val_loss: 0.3690\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3326 - val_loss: 0.3713\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3331 - val_loss: 0.3718\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3319 - val_loss: 0.3726\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3695\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3290 - val_loss: 0.3638\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3268 - val_loss: 0.3651\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3254 - val_loss: 0.3690\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3236 - val_loss: 0.3661\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3222 - val_loss: 0.3608\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3216 - val_loss: 0.3597\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.3593\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3192 - val_loss: 0.3626\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3168 - val_loss: 0.3612\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3162 - val_loss: 0.3606\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3584\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.3584\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.3595\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3123 - val_loss: 0.3531\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.3522\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3096 - val_loss: 0.3559\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3093 - val_loss: 0.3505\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3076 - val_loss: 0.3545\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.3558\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3064 - val_loss: 0.3507\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.3595\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3478\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3466\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3029 - val_loss: 0.3514\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3479\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3455\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2996 - val_loss: 0.3439\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3477\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2990 - val_loss: 0.3427\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2974 - val_loss: 0.3412\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2976 - val_loss: 0.3422\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2969 - val_loss: 0.3404\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2957 - val_loss: 0.3425\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.3475\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2946 - val_loss: 0.3375\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2934 - val_loss: 0.3439\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2930 - val_loss: 0.3406\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2917 - val_loss: 0.3550\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2905 - val_loss: 0.3439\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.3427\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2912 - val_loss: 0.3372\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.3418\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2895 - val_loss: 0.3393\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2885 - val_loss: 0.3355\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2876 - val_loss: 0.3421\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2883 - val_loss: 0.3382\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2875 - val_loss: 0.3339\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.3484\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.3375\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2859 - val_loss: 0.3332\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2840 - val_loss: 0.3301\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.3337\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 0.3333\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2833 - val_loss: 0.3311\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2823 - val_loss: 0.3302\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2829 - val_loss: 0.3316\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3065\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  48.9s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8498 - val_loss: 0.5837\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.4879\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4505 - val_loss: 0.4529\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4524\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4300\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.4182\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3876 - val_loss: 0.4078\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.4070\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.3983\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.3948\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3864\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3856\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3830\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3741\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3403 - val_loss: 0.3904\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3632\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3341 - val_loss: 0.3645\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3269 - val_loss: 0.3577\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3251 - val_loss: 0.3597\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.3525\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3191 - val_loss: 0.3525\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3156 - val_loss: 0.3502\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3118 - val_loss: 0.3613\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3176 - val_loss: 0.3537\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3121 - val_loss: 0.3514\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3096 - val_loss: 0.3449\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3062 - val_loss: 0.3732\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3046 - val_loss: 0.3610\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.3394\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2986 - val_loss: 0.3486\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2970 - val_loss: 0.3524\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2960 - val_loss: 0.3355\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2947 - val_loss: 0.3307\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.3311\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2883 - val_loss: 0.3360\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2916 - val_loss: 0.3354\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2875 - val_loss: 0.3358\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2875 - val_loss: 0.3273\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2851 - val_loss: 0.3657\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2852 - val_loss: 0.3377\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2845 - val_loss: 0.3348\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2831 - val_loss: 0.3337\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2821 - val_loss: 0.3453\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2809 - val_loss: 0.3299\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2808 - val_loss: 0.3300\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2809 - val_loss: 0.3305\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2791 - val_loss: 0.3286\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2756 - val_loss: 0.3378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000022F7F65B8E0>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 74, 'n_hidden': 3, 'learning_rate': 0.005803602934201024}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.30289607246716815"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x22f0433a2b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 927us/step - loss: 0.3127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3126693069934845"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x22f5d31f040>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 0s - loss: 0.2095WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "162/162 [==============================] - 0s 867us/step - loss: 0.3127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3126693069934845"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

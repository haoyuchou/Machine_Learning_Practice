{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0392219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0dbb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x190dd976460>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "# change the default to He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98c1164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x190e80f1f70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',distribution='uniform')\n",
    "# we want He initialization base on fan_avg, not fan_in\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c5203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59637da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9943375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea619cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train a neural network on Fashion MNIST using the Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c1afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c64e36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),    # activation\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),    # activation\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "# put the activation after the layer you want to apply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f020a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",  # multiclassifier\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3), # 0.001, start from a very small learning rate\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f840ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7658\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6816 - accuracy: 0.7720 - val_loss: 0.6427 - val_accuracy: 0.7898\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8064\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5832 - accuracy: 0.8074 - val_loss: 0.5582 - val_accuracy: 0.8198\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5553 - accuracy: 0.8156 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5338 - accuracy: 0.8224 - val_loss: 0.5157 - val_accuracy: 0.8302\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5173 - accuracy: 0.8272 - val_loss: 0.5079 - val_accuracy: 0.8286\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5040 - accuracy: 0.8290 - val_loss: 0.4895 - val_accuracy: 0.8388\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4817 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "hitory = model.fit(X_train, y_train, epochs=10,\n",
    "                  validation_data=(X_valid, y_valid))\n",
    "# according to the loss, there is definately room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5600bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eddd83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),    # activation\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),    # activation\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0164d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "# the compile part is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f91b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 1.3461 - accuracy: 0.6209 - val_loss: 0.9255 - val_accuracy: 0.7184\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8197 - accuracy: 0.7355 - val_loss: 0.7305 - val_accuracy: 0.7632\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6966 - accuracy: 0.7693 - val_loss: 0.6564 - val_accuracy: 0.7884\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6331 - accuracy: 0.7910 - val_loss: 0.6003 - val_accuracy: 0.8046\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5917 - accuracy: 0.8056 - val_loss: 0.5656 - val_accuracy: 0.8184\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5618 - accuracy: 0.8135 - val_loss: 0.5406 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5390 - accuracy: 0.8206 - val_loss: 0.5196 - val_accuracy: 0.8312\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5213 - accuracy: 0.8256 - val_loss: 0.5113 - val_accuracy: 0.8316\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5070 - accuracy: 0.8288 - val_loss: 0.4916 - val_accuracy: 0.8378\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4945 - accuracy: 0.8315 - val_loss: 0.4826 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history_one = model.fit(X_train, y_train, epochs =10,\n",
    "                       validation_data=(X_valid, y_valid))\n",
    "# there is also room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "700ffce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try SELU this time\n",
    "# Using SELU, even 1000 layer DNN preserve roughly 0 mean and std 1,\n",
    "# avoiding the exploding/vanishing gradients problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333ec96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST with 100 hidden layers, using the SELU activation function\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b458ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "066cb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# add many layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fa55c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767c5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!  scale the inputs to mean 0 and standard deviation 1\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "# Use these two for input normalization\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4456d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 42s 25ms/step - loss: 1.3655 - accuracy: 0.4703 - val_loss: 0.8430 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 41s 24ms/step - loss: 0.7593 - accuracy: 0.7310 - val_loss: 0.6394 - val_accuracy: 0.7784\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 41s 24ms/step - loss: 0.6224 - accuracy: 0.7792 - val_loss: 0.7451 - val_accuracy: 0.6906\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 40s 23ms/step - loss: 0.5510 - accuracy: 0.8069 - val_loss: 0.4976 - val_accuracy: 0.8286\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 40s 24ms/step - loss: 0.5242 - accuracy: 0.8198 - val_loss: 0.5051 - val_accuracy: 0.8240\n"
     ]
    }
   ],
   "source": [
    "history_two = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))\n",
    "\n",
    "# It is really slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "457933e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that's compare to ReLU\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "846d1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# See what happen if we also provide many layers for ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d53794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d25b4a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 1.7943 - accuracy: 0.2667 - val_loss: 1.3639 - val_accuracy: 0.3538\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 1.1514 - accuracy: 0.5130 - val_loss: 0.9178 - val_accuracy: 0.6464\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.9737 - accuracy: 0.6063 - val_loss: 0.8336 - val_accuracy: 0.6830\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.8294 - accuracy: 0.6710 - val_loss: 0.7792 - val_accuracy: 0.6954\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.8674 - accuracy: 0.6598 - val_loss: 0.8817 - val_accuracy: 0.6522\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))\n",
    "#  suffered from the vanishing/exploding gradients problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93ff08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),  # Apply as first layer after flatten\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),  # After activation function\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),  # After activation function\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0c575b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# adds 4 parameters per input, 3136 = 4*784\n",
    "# (3136 + 1200 + 400)/2 = 2368, which is non-trainable\n",
    "# The last two parameters, μ and σ, are the moving averages; they are not affected by backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0e0a09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]\n",
    "# first two trainable\n",
    "# last two non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ef3b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bn1.updates is deprecated\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47d075c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8750 - accuracy: 0.7124 - val_loss: 0.5525 - val_accuracy: 0.8230\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5753 - accuracy: 0.8029 - val_loss: 0.4724 - val_accuracy: 0.8472\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5189 - accuracy: 0.8205 - val_loss: 0.4375 - val_accuracy: 0.8552\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4827 - accuracy: 0.8323 - val_loss: 0.4151 - val_accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4565 - accuracy: 0.8405 - val_loss: 0.3996 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4397 - accuracy: 0.8475 - val_loss: 0.3866 - val_accuracy: 0.8694\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4242 - accuracy: 0.8513 - val_loss: 0.3762 - val_accuracy: 0.8712\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4144 - accuracy: 0.8540 - val_loss: 0.3713 - val_accuracy: 0.8738\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4024 - accuracy: 0.8581 - val_loss: 0.3631 - val_accuracy: 0.8754\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3914 - accuracy: 0.8623 - val_loss: 0.3572 - val_accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "history_three = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "454c35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BN layer before activation function\n",
    "# remove the activation function from the hidden layers and add them as separate layers after the BN layers\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bb36680",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a148e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.0317 - accuracy: 0.6757 - val_loss: 0.6767 - val_accuracy: 0.7816\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6790 - accuracy: 0.7792 - val_loss: 0.5566 - val_accuracy: 0.8180\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5960 - accuracy: 0.8038 - val_loss: 0.5007 - val_accuracy: 0.8360\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5447 - accuracy: 0.8193 - val_loss: 0.4666 - val_accuracy: 0.8448\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5109 - accuracy: 0.8279 - val_loss: 0.4434 - val_accuracy: 0.8536\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4898 - accuracy: 0.8337 - val_loss: 0.4263 - val_accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4712 - accuracy: 0.8397 - val_loss: 0.4131 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4560 - accuracy: 0.8439 - val_loss: 0.4035 - val_accuracy: 0.8606\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4441 - accuracy: 0.8474 - val_loss: 0.3943 - val_accuracy: 0.8640\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4332 - accuracy: 0.8505 - val_loss: 0.3875 - val_accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f952ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88d311f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "519adee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfa94389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6] # y except sandals or shirts\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7, went from 10 classes to 8 classes\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d7c75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_A: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "# X_train_B: a much smaller training set of just the first 200 images of sandals or shirts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "663b3406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7535bf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca7146d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7965f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4e5e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95ef9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):  # 5 hideen layers\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc0881",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c78f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74513c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.5927 - accuracy: 0.8104 - val_loss: 0.3896 - val_accuracy: 0.8667\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3523 - accuracy: 0.8786 - val_loss: 0.3289 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3170 - accuracy: 0.8894 - val_loss: 0.3014 - val_accuracy: 0.8994\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2973 - accuracy: 0.8974 - val_loss: 0.2893 - val_accuracy: 0.9016\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2835 - accuracy: 0.9020 - val_loss: 0.2774 - val_accuracy: 0.9063\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2729 - accuracy: 0.9062 - val_loss: 0.2734 - val_accuracy: 0.9071\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2641 - accuracy: 0.9093 - val_loss: 0.2722 - val_accuracy: 0.9081\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2573 - accuracy: 0.9128 - val_loss: 0.2589 - val_accuracy: 0.9143\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2518 - accuracy: 0.9135 - val_loss: 0.2563 - val_accuracy: 0.9145\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2469 - accuracy: 0.9154 - val_loss: 0.2543 - val_accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2422 - accuracy: 0.9177 - val_loss: 0.2497 - val_accuracy: 0.9148\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2383 - accuracy: 0.9190 - val_loss: 0.2514 - val_accuracy: 0.9128\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2350 - accuracy: 0.9197 - val_loss: 0.2445 - val_accuracy: 0.9158\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2316 - accuracy: 0.9213 - val_loss: 0.2416 - val_accuracy: 0.9175\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2288 - accuracy: 0.9212 - val_loss: 0.2448 - val_accuracy: 0.9190\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2255 - accuracy: 0.9224 - val_loss: 0.2387 - val_accuracy: 0.9198\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2231 - accuracy: 0.9233 - val_loss: 0.2409 - val_accuracy: 0.9175\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2201 - accuracy: 0.9244 - val_loss: 0.2428 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2178 - accuracy: 0.9253 - val_loss: 0.2330 - val_accuracy: 0.9203\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2156 - accuracy: 0.9263 - val_loss: 0.2335 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4972e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model A\n",
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "700a4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a new model for this task (let’s call it model B) with the same architecture as model A\n",
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))  # Last chapter point out the advantage of SELU\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57ddc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab6ec29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.9573 - accuracy: 0.4650 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5692 - accuracy: 0.7450 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8650 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8950 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.9250 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3081 - accuracy: 0.9300 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2800 - accuracy: 0.9350 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.9450 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2362 - accuracy: 0.9550 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2188 - accuracy: 0.9600 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2036 - accuracy: 0.9700 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1898 - accuracy: 0.9700 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1773 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1668 - accuracy: 0.9800 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 1.00 - 0s 8ms/step - loss: 0.1570 - accuracy: 0.9900 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1481 - accuracy: 0.9900 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9900 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1334 - accuracy: 0.9900 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1268 - accuracy: 0.9900 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1208 - accuracy: 0.9900 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a602aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e708dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model A and create a new model based on that model’s layers\n",
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75c1efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid affecting model A\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01d112db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n",
    "metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd100f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4656 - accuracy: 0.7500 - val_loss: 0.3568 - val_accuracy: 0.8469\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.9400 - val_loss: 0.2351 - val_accuracy: 0.9422\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1825 - accuracy: 0.9650 - val_loss: 0.1774 - val_accuracy: 0.9655\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.9800 - val_loss: 0.1447 - val_accuracy: 0.9828\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.1119 - accuracy: 0.9900 - val_loss: 0.1284 - val_accuracy: 0.9848\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0975 - accuracy: 0.9950 - val_loss: 0.1153 - val_accuracy: 0.9878\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9888\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9888\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9899\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9899\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9909\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9909\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9909\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9909\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9909\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9909\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9909\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9909\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9909\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "# train the model for a few epochs, then unfreeze the reused layers \n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "323000a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1408407837152481, 0.9704999923706055]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#　evaluate test set\n",
    "# oroginal model B\n",
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f8b04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05228932201862335, 0.9940000176429749]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transfer learning model\n",
    "model_B_on_A.evaluate(X_test_B, y_test_B)\n",
    "# improve a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d795db08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.538461538461503"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100 - 97.05) / (100 - 99.35)\n",
    "# the improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cfaf4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "716b6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum optimization\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25178eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesterov Accelerated Gradient\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85ee7872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaGrad\n",
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ba224d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSProp\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "973ed977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimizer\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "948233d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamax Optimization\n",
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d2c9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nadam Optimization\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76ad53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d91ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fda19f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4855 - accuracy: 0.8304 - val_loss: 0.4029 - val_accuracy: 0.8592\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3782 - accuracy: 0.8657 - val_loss: 0.3715 - val_accuracy: 0.8728\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3459 - accuracy: 0.8770 - val_loss: 0.3750 - val_accuracy: 0.8752\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3251 - accuracy: 0.8827 - val_loss: 0.3502 - val_accuracy: 0.8796\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3102 - accuracy: 0.8889 - val_loss: 0.3448 - val_accuracy: 0.8778\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2967 - accuracy: 0.8933 - val_loss: 0.3413 - val_accuracy: 0.8828\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2868 - accuracy: 0.8973 - val_loss: 0.3357 - val_accuracy: 0.8880\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2778 - accuracy: 0.9009 - val_loss: 0.3411 - val_accuracy: 0.8836\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2698 - accuracy: 0.9021 - val_loss: 0.3294 - val_accuracy: 0.8882\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2628 - accuracy: 0.9048 - val_loss: 0.3264 - val_accuracy: 0.8880\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2571 - accuracy: 0.9081 - val_loss: 0.3272 - val_accuracy: 0.8872\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2513 - accuracy: 0.9104 - val_loss: 0.3337 - val_accuracy: 0.8836\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2461 - accuracy: 0.9128 - val_loss: 0.3262 - val_accuracy: 0.8894\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2422 - accuracy: 0.9134 - val_loss: 0.3291 - val_accuracy: 0.8886\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2375 - accuracy: 0.9155 - val_loss: 0.3245 - val_accuracy: 0.8876\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2336 - accuracy: 0.9173 - val_loss: 0.3207 - val_accuracy: 0.8906\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2300 - accuracy: 0.9182 - val_loss: 0.3240 - val_accuracy: 0.8900\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2263 - accuracy: 0.9197 - val_loss: 0.3190 - val_accuracy: 0.8938\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2233 - accuracy: 0.9208 - val_loss: 0.3232 - val_accuracy: 0.8904\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2200 - accuracy: 0.9224 - val_loss: 0.3212 - val_accuracy: 0.8920\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2169 - accuracy: 0.9232 - val_loss: 0.3209 - val_accuracy: 0.8914\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2143 - accuracy: 0.9240 - val_loss: 0.3184 - val_accuracy: 0.8944\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2117 - accuracy: 0.9252 - val_loss: 0.3196 - val_accuracy: 0.8908\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2089 - accuracy: 0.9260 - val_loss: 0.3217 - val_accuracy: 0.8892\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2070 - accuracy: 0.9263 - val_loss: 0.3215 - val_accuracy: 0.8916\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a29c8d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-4    # power scheduling\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b67f85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59893973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a414b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e5ce0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "228d504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8480 - accuracy: 0.7550 - val_loss: 0.9785 - val_accuracy: 0.7528\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6713 - accuracy: 0.7948 - val_loss: 0.6585 - val_accuracy: 0.8264\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6148 - accuracy: 0.8125 - val_loss: 0.8588 - val_accuracy: 0.7736\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5350 - accuracy: 0.8324 - val_loss: 0.4969 - val_accuracy: 0.8446\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5106 - accuracy: 0.8411 - val_loss: 0.5831 - val_accuracy: 0.8470\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4513 - accuracy: 0.8571 - val_loss: 0.5781 - val_accuracy: 0.8538\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4119 - accuracy: 0.8675 - val_loss: 0.5293 - val_accuracy: 0.8642\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3807 - accuracy: 0.8773 - val_loss: 0.5304 - val_accuracy: 0.8408\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3542 - accuracy: 0.8833 - val_loss: 0.4801 - val_accuracy: 0.8602\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3288 - accuracy: 0.8912 - val_loss: 0.4827 - val_accuracy: 0.8794\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3090 - accuracy: 0.8974 - val_loss: 0.4315 - val_accuracy: 0.8740\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2860 - accuracy: 0.9026 - val_loss: 0.4882 - val_accuracy: 0.8762\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2628 - accuracy: 0.9104 - val_loss: 0.4683 - val_accuracy: 0.8838\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2400 - accuracy: 0.9180 - val_loss: 0.4604 - val_accuracy: 0.8858\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2275 - accuracy: 0.9229 - val_loss: 0.4662 - val_accuracy: 0.8850\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2058 - accuracy: 0.9300 - val_loss: 0.4862 - val_accuracy: 0.8880\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1974 - accuracy: 0.9317 - val_loss: 0.4759 - val_accuracy: 0.8850\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1804 - accuracy: 0.9378 - val_loss: 0.4689 - val_accuracy: 0.8868\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1704 - accuracy: 0.9423 - val_loss: 0.4654 - val_accuracy: 0.8922\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1581 - accuracy: 0.9457 - val_loss: 0.4722 - val_accuracy: 0.8876\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1471 - accuracy: 0.9495 - val_loss: 0.5516 - val_accuracy: 0.8878\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1388 - accuracy: 0.9522 - val_loss: 0.5084 - val_accuracy: 0.8920\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1289 - accuracy: 0.9565 - val_loss: 0.5421 - val_accuracy: 0.8888\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1209 - accuracy: 0.9591 - val_loss: 0.6116 - val_accuracy: 0.8868\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1146 - accuracy: 0.9611 - val_loss: 0.5522 - val_accuracy: 0.8928\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d1d25ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schedule function can take the current learning rate as a second argument:\n",
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b621831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piecewise Constant Scheduling\n",
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9ef7e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8839 - accuracy: 0.7489 - val_loss: 0.8820 - val_accuracy: 0.7236\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.8297 - accuracy: 0.7622 - val_loss: 1.2858 - val_accuracy: 0.6668\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8822 - accuracy: 0.7533 - val_loss: 1.6342 - val_accuracy: 0.6094\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8347 - accuracy: 0.7595 - val_loss: 0.6871 - val_accuracy: 0.8082\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.9767 - accuracy: 0.7133 - val_loss: 1.5006 - val_accuracy: 0.5644\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.7129 - accuracy: 0.7588 - val_loss: 0.7003 - val_accuracy: 0.8112\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5761 - accuracy: 0.8209 - val_loss: 0.6265 - val_accuracy: 0.8158\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5450 - accuracy: 0.8321 - val_loss: 0.7446 - val_accuracy: 0.7980\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5341 - accuracy: 0.8353 - val_loss: 0.6708 - val_accuracy: 0.7812\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5288 - accuracy: 0.8419 - val_loss: 0.5816 - val_accuracy: 0.8418\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4969 - accuracy: 0.8440 - val_loss: 0.5971 - val_accuracy: 0.8420\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4854 - accuracy: 0.8540 - val_loss: 0.6301 - val_accuracy: 0.8170\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4892 - accuracy: 0.8503 - val_loss: 0.6438 - val_accuracy: 0.8388\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4701 - accuracy: 0.8562 - val_loss: 0.6553 - val_accuracy: 0.8372\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4678 - accuracy: 0.8582 - val_loss: 0.7041 - val_accuracy: 0.8422\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3362 - accuracy: 0.8905 - val_loss: 0.6173 - val_accuracy: 0.8666\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3131 - accuracy: 0.8988 - val_loss: 0.6310 - val_accuracy: 0.8616\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3006 - accuracy: 0.9018 - val_loss: 0.6040 - val_accuracy: 0.8646\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2901 - accuracy: 0.9052 - val_loss: 0.6439 - val_accuracy: 0.8666\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2841 - accuracy: 0.9083 - val_loss: 0.6180 - val_accuracy: 0.8688\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2716 - accuracy: 0.9121 - val_loss: 0.6166 - val_accuracy: 0.8682\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2654 - accuracy: 0.9146 - val_loss: 0.6455 - val_accuracy: 0.8706\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2615 - accuracy: 0.9156 - val_loss: 0.6283 - val_accuracy: 0.8644\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2544 - accuracy: 0.9180 - val_loss: 0.6701 - val_accuracy: 0.8650\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2518 - accuracy: 0.9194 - val_loss: 0.6701 - val_accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47a07275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0b11ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.9282 - accuracy: 0.7330 - val_loss: 1.0504 - val_accuracy: 0.6664\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.9055 - accuracy: 0.7077 - val_loss: 0.8664 - val_accuracy: 0.7178\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.9217 - accuracy: 0.6941 - val_loss: 1.0393 - val_accuracy: 0.6920\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.0725 - accuracy: 0.6492 - val_loss: 1.1998 - val_accuracy: 0.5408\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.0555 - accuracy: 0.6142 - val_loss: 0.9980 - val_accuracy: 0.6174\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8560 - accuracy: 0.6482 - val_loss: 0.8538 - val_accuracy: 0.6650\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.8167 - accuracy: 0.6624 - val_loss: 0.9097 - val_accuracy: 0.6520\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7865 - accuracy: 0.6862 - val_loss: 0.7341 - val_accuracy: 0.7632\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6166 - accuracy: 0.7588 - val_loss: 0.8117 - val_accuracy: 0.7458\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5945 - accuracy: 0.7623 - val_loss: 0.7453 - val_accuracy: 0.7582\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6025 - accuracy: 0.7666 - val_loss: 0.6656 - val_accuracy: 0.7776\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5869 - accuracy: 0.7707 - val_loss: 0.7083 - val_accuracy: 0.7722\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5772 - accuracy: 0.7747 - val_loss: 0.6653 - val_accuracy: 0.7724\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5860 - accuracy: 0.7760 - val_loss: 0.6628 - val_accuracy: 0.7756\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5722 - accuracy: 0.7779 - val_loss: 0.7233 - val_accuracy: 0.7562\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4578 - accuracy: 0.8110 - val_loss: 0.5718 - val_accuracy: 0.8036\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4314 - accuracy: 0.8191 - val_loss: 0.6090 - val_accuracy: 0.7908\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4168 - accuracy: 0.8257 - val_loss: 0.5952 - val_accuracy: 0.8116\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4059 - accuracy: 0.8304 - val_loss: 0.5850 - val_accuracy: 0.8128\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3964 - accuracy: 0.8344 - val_loss: 0.5932 - val_accuracy: 0.8012\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3895 - accuracy: 0.8368 - val_loss: 0.6049 - val_accuracy: 0.8022\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3823 - accuracy: 0.8387 - val_loss: 0.5895 - val_accuracy: 0.8222\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3734 - accuracy: 0.8424 - val_loss: 0.5960 - val_accuracy: 0.8098\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3639 - accuracy: 0.8470 - val_loss: 0.6168 - val_accuracy: 0.8218\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3589 - accuracy: 0.8463 - val_loss: 0.6105 - val_accuracy: 0.8096\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f217a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ef767ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ff87602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00944067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5921 - accuracy: 0.8083 - val_loss: 0.4691 - val_accuracy: 0.8518\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5030 - accuracy: 0.8387 - val_loss: 0.6181 - val_accuracy: 0.8346\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5166 - accuracy: 0.8421 - val_loss: 0.5722 - val_accuracy: 0.8498\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4964 - accuracy: 0.8504 - val_loss: 0.4432 - val_accuracy: 0.8576\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5157 - accuracy: 0.8485 - val_loss: 0.5207 - val_accuracy: 0.8528\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5048 - accuracy: 0.8550 - val_loss: 0.6121 - val_accuracy: 0.8606\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5345 - accuracy: 0.8550 - val_loss: 0.6298 - val_accuracy: 0.8420\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5110 - accuracy: 0.8579 - val_loss: 0.5695 - val_accuracy: 0.8342\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5199 - accuracy: 0.8580 - val_loss: 0.7268 - val_accuracy: 0.8238\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2996 - accuracy: 0.8969 - val_loss: 0.4029 - val_accuracy: 0.8836\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2463 - accuracy: 0.9108 - val_loss: 0.4010 - val_accuracy: 0.8898\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2256 - accuracy: 0.9167 - val_loss: 0.4556 - val_accuracy: 0.8764\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2091 - accuracy: 0.9231 - val_loss: 0.4646 - val_accuracy: 0.8844\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1977 - accuracy: 0.9268 - val_loss: 0.5044 - val_accuracy: 0.8696\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1887 - accuracy: 0.9295 - val_loss: 0.4849 - val_accuracy: 0.8826\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1786 - accuracy: 0.9327 - val_loss: 0.5009 - val_accuracy: 0.8896\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1248 - accuracy: 0.9504 - val_loss: 0.4750 - val_accuracy: 0.8912\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1095 - accuracy: 0.9558 - val_loss: 0.4829 - val_accuracy: 0.8926\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1024 - accuracy: 0.9596 - val_loss: 0.5022 - val_accuracy: 0.8952\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0947 - accuracy: 0.9624 - val_loss: 0.5092 - val_accuracy: 0.8902\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0893 - accuracy: 0.9647 - val_loss: 0.5323 - val_accuracy: 0.8936\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0710 - accuracy: 0.9729 - val_loss: 0.5417 - val_accuracy: 0.8964\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0657 - accuracy: 0.9751 - val_loss: 0.5557 - val_accuracy: 0.8974\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0618 - accuracy: 0.9763 - val_loss: 0.5618 - val_accuracy: 0.8954\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0596 - accuracy: 0.9769 - val_loss: 0.5823 - val_accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91f7e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras schedulers\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ffd53ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d52122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4894 - accuracy: 0.8276 - val_loss: 0.4095 - val_accuracy: 0.8606\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3820 - accuracy: 0.8653 - val_loss: 0.3741 - val_accuracy: 0.8690\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3487 - accuracy: 0.8767 - val_loss: 0.3726 - val_accuracy: 0.8688\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3265 - accuracy: 0.8836 - val_loss: 0.3493 - val_accuracy: 0.8800\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3105 - accuracy: 0.8895 - val_loss: 0.3430 - val_accuracy: 0.8790\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2959 - accuracy: 0.8952 - val_loss: 0.3412 - val_accuracy: 0.8812\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2855 - accuracy: 0.8987 - val_loss: 0.3353 - val_accuracy: 0.8816\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2761 - accuracy: 0.9017 - val_loss: 0.3361 - val_accuracy: 0.8820\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2678 - accuracy: 0.9058 - val_loss: 0.3263 - val_accuracy: 0.8844\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2608 - accuracy: 0.9067 - val_loss: 0.3237 - val_accuracy: 0.8858\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2552 - accuracy: 0.9091 - val_loss: 0.3248 - val_accuracy: 0.8866\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2497 - accuracy: 0.9126 - val_loss: 0.3298 - val_accuracy: 0.8814\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2450 - accuracy: 0.9137 - val_loss: 0.3216 - val_accuracy: 0.8876\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2416 - accuracy: 0.9145 - val_loss: 0.3219 - val_accuracy: 0.8868\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2376 - accuracy: 0.9167 - val_loss: 0.3206 - val_accuracy: 0.8884\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2344 - accuracy: 0.9175 - val_loss: 0.3182 - val_accuracy: 0.8890\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2317 - accuracy: 0.9187 - val_loss: 0.3195 - val_accuracy: 0.8908\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2292 - accuracy: 0.9197 - val_loss: 0.3167 - val_accuracy: 0.8906\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2270 - accuracy: 0.9208 - val_loss: 0.3196 - val_accuracy: 0.8896\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2251 - accuracy: 0.9220 - val_loss: 0.3167 - val_accuracy: 0.8900\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2230 - accuracy: 0.9224 - val_loss: 0.3179 - val_accuracy: 0.8902\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2217 - accuracy: 0.9224 - val_loss: 0.3162 - val_accuracy: 0.8918\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2202 - accuracy: 0.9232 - val_loss: 0.3170 - val_accuracy: 0.8896\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2189 - accuracy: 0.9241 - val_loss: 0.3165 - val_accuracy: 0.8902\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2180 - accuracy: 0.9240 - val_loss: 0.3164 - val_accuracy: 0.8918\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "97f3626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For piecewise constant scheduling\n",
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "860c5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Cycle scheduling\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c981eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a55233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0e6665bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5203 - accuracy: 0.8173 - val_loss: 0.4169 - val_accuracy: 0.8582\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3974 - accuracy: 0.8586 - val_loss: 0.3778 - val_accuracy: 0.8698\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3617 - accuracy: 0.8713 - val_loss: 0.4036 - val_accuracy: 0.8582\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3386 - accuracy: 0.8774 - val_loss: 0.3508 - val_accuracy: 0.8764\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3195 - accuracy: 0.8848 - val_loss: 0.3474 - val_accuracy: 0.8734\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2979 - accuracy: 0.8913 - val_loss: 0.3476 - val_accuracy: 0.8786\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2858 - accuracy: 0.8950 - val_loss: 0.3914 - val_accuracy: 0.8634\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2738 - accuracy: 0.8999 - val_loss: 0.3751 - val_accuracy: 0.8702\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2593 - accuracy: 0.9041 - val_loss: 0.3342 - val_accuracy: 0.8834\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2514 - accuracy: 0.9059 - val_loss: 0.3502 - val_accuracy: 0.8830\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2401 - accuracy: 0.9101 - val_loss: 0.3353 - val_accuracy: 0.8856\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2266 - accuracy: 0.9163 - val_loss: 0.3746 - val_accuracy: 0.8750\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2028 - accuracy: 0.9246 - val_loss: 0.3478 - val_accuracy: 0.8838\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1842 - accuracy: 0.9318 - val_loss: 0.3657 - val_accuracy: 0.8784\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1648 - accuracy: 0.9389 - val_loss: 0.3472 - val_accuracy: 0.8894\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1504 - accuracy: 0.9448 - val_loss: 0.3471 - val_accuracy: 0.8916\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1328 - accuracy: 0.9524 - val_loss: 0.3538 - val_accuracy: 0.8926\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1183 - accuracy: 0.9573 - val_loss: 0.3558 - val_accuracy: 0.8922\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1047 - accuracy: 0.9630 - val_loss: 0.3510 - val_accuracy: 0.8986\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0926 - accuracy: 0.9689 - val_loss: 0.3578 - val_accuracy: 0.8952\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9737 - val_loss: 0.3646 - val_accuracy: 0.8980\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0729 - accuracy: 0.9769 - val_loss: 0.3634 - val_accuracy: 0.8972\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0660 - accuracy: 0.9807 - val_loss: 0.3631 - val_accuracy: 0.8986\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0618 - accuracy: 0.9822 - val_loss: 0.3649 - val_accuracy: 0.8964\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0590 - accuracy: 0.9841 - val_loss: 0.3641 - val_accuracy: 0.8982\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a02cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding Overfitting Through Regularization\n",
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba05b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "activation=\"elu\",\n",
    "kernel_initializer=\"he_normal\",\n",
    "kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64646817",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "RegularizedDense(300),\n",
    "RegularizedDense(100),\n",
    "RegularizedDense(10, activation=\"softmax\",\n",
    "kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1527394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 1.5956 - accuracy: 0.8124 - val_loss: 0.7169 - val_accuracy: 0.8340\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.7197 - accuracy: 0.8274 - val_loss: 0.6850 - val_accuracy: 0.8376\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "704580a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "adef9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5597 - accuracy: 0.8059 - val_loss: 0.3672 - val_accuracy: 0.8652\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4229 - accuracy: 0.8453 - val_loss: 0.3460 - val_accuracy: 0.8698\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2aa117ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha Dropout\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2b3551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6654 - accuracy: 0.7599 - val_loss: 0.5935 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5608 - accuracy: 0.7929 - val_loss: 0.5566 - val_accuracy: 0.8398\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5284 - accuracy: 0.8056 - val_loss: 0.4832 - val_accuracy: 0.8584\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5073 - accuracy: 0.8118 - val_loss: 0.4605 - val_accuracy: 0.8600\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4924 - accuracy: 0.8179 - val_loss: 0.4584 - val_accuracy: 0.8562\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4871 - accuracy: 0.8184 - val_loss: 0.4739 - val_accuracy: 0.8598\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4714 - accuracy: 0.8244 - val_loss: 0.4708 - val_accuracy: 0.8662\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4635 - accuracy: 0.8283 - val_loss: 0.4710 - val_accuracy: 0.8622\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4579 - accuracy: 0.8307 - val_loss: 0.4158 - val_accuracy: 0.8688\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4521 - accuracy: 0.8324 - val_loss: 0.4576 - val_accuracy: 0.8676\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4482 - accuracy: 0.8327 - val_loss: 0.4178 - val_accuracy: 0.8688\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4472 - accuracy: 0.8333 - val_loss: 0.5403 - val_accuracy: 0.8514\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4428 - accuracy: 0.8353 - val_loss: 0.4483 - val_accuracy: 0.8704\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4323 - accuracy: 0.8399 - val_loss: 0.4511 - val_accuracy: 0.8688\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4322 - accuracy: 0.8373 - val_loss: 0.4408 - val_accuracy: 0.8690\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4302 - accuracy: 0.8413 - val_loss: 0.4046 - val_accuracy: 0.8778\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4261 - accuracy: 0.8415 - val_loss: 0.5485 - val_accuracy: 0.8580\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4260 - accuracy: 0.8424 - val_loss: 0.4904 - val_accuracy: 0.8760\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4206 - accuracy: 0.8451 - val_loss: 0.4876 - val_accuracy: 0.8732\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4248 - accuracy: 0.8418 - val_loss: 0.3899 - val_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)    # self-normalized?\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bfbbd0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4313259422779083, 0.8679999709129333]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "598a7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3194 - accuracy: 0.8903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31936410069465637, 0.8902727365493774]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0454adba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4174 - accuracy: 0.8452\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "748c7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC Dropout\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e837174",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)\n",
    "# setting training=True to\n",
    "# ensure that the Dropout layer is active, and stack the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "89db459e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)\n",
    "# dropout off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "db0ce763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.17, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.83, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.  , 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.05, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.13, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.4 , 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.2 , 0.  , 0.51]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.46, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.69, 0.  , 0.04, 0.  , 0.27]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.06, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.06, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.41, 0.  , 0.  , 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.76, 0.  , 0.06, 0.  , 0.18]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.03, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.04, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.  , 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.78, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.  , 0.06, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.6 , 0.  , 0.03, 0.  , 0.37]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.93, 0.  , 0.01, 0.  , 0.06]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.22, 0.  , 0.28]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.19, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.72, 0.  , 0.03, 0.  , 0.26]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.55, 0.  , 0.  , 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.56, 0.  , 0.26]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.01, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.01, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.02, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.76, 0.  , 0.14, 0.  , 0.1 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.02, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.41, 0.  , 0.41]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.04, 0.  , 0.37]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.08, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.  , 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.01, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.07, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.12, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.3 , 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.59, 0.  , 0.13, 0.  , 0.28]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.16, 0.  , 0.27]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.01, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.38, 0.  , 0.02, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.16, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.19, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.8 , 0.  , 0.18]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.74, 0.  , 0.24]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.05, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.51, 0.  , 0.04, 0.  , 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.02, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.02, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.02, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.13, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.  , 0.03, 0.  , 0.52]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.05, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.1 , 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.01, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.03, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.04, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.04, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.  , 0.27, 0.  , 0.3 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.18, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.  , 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.06, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.05, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.01]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.01, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.03, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.94, 0.  , 0.02, 0.  , 0.04]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.66, 0.  , 0.02, 0.  , 0.32]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.  , 0.02, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.51, 0.  , 0.01, 0.  , 0.47]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.01, 0.  , 0.49]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)\n",
    "# This is stacked\n",
    "# dropout activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9a5bed5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.1 , 0.  , 0.69]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)\n",
    "# average the first dimension\n",
    "# still thinks belong to class 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eb94c457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1c03a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation of the probability estimates\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "169a5edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.17, 0.  , 0.28]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_std[:1], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6132b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06ad0b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy\n",
    "# actualliy boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7c490e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3eba51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d895ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max norm\n",
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5900f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2f8979d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33ee1c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4744 - accuracy: 0.8335 - val_loss: 0.3619 - val_accuracy: 0.8664\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3545 - accuracy: 0.8712 - val_loss: 0.3808 - val_accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707cbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
